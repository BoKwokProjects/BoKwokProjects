{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMpbYHzI5PtW"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39882194"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "from collections import namedtuple\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import collections\n",
    "import math\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6061aGw4pM0w"
   },
   "source": [
    "If you want the result to be reproducible, you will need to set the seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QrPC2sxvRkvX"
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSV0OKw4pY14"
   },
   "source": [
    "Mount to Google drive and unpack your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-h6147Klo6y",
    "outputId": "e1eb941a-0260-40f8-c2a1-6dc1e889596a"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4B7PKK1Y1FYV"
   },
   "outputs": [],
   "source": [
    "# Unpack the dataset zip file\n",
    "shutil.unpack_archive(\"/content/drive/MyDrive/Deep Learning/ISIC_balanced_split.zip\", \"/content/drive/MyDrive/Deep Learning/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIKPVr-XyUL6"
   },
   "source": [
    "Run calculation on mean and standard deviation of my train dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjv-NBDLp4No"
   },
   "source": [
    "This is an additional code to check the mean and standard deviation of your dataset - you can then use it to replace the values in transforms.Normalize to improve your work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nbsqpyy1gFze",
    "outputId": "74747ff9-31be-4697-9316-01b5bb4bdc42"
   },
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(root = '/content/drive/My Drive/Deep Learning/ISIC_balanced_split/train/',\n",
    "                                  transform = transforms.ToTensor())\n",
    "\n",
    "means = torch.zeros(3)\n",
    "stds = torch.zeros(3)\n",
    "\n",
    "for img, label in train_data:\n",
    "    means += torch.mean(img, dim = (1,2))\n",
    "    stds += torch.std(img, dim = (1,2))\n",
    "\n",
    "means /= len(train_data)\n",
    "stds /= len(train_data)\n",
    "\n",
    "print(f'Calculated means: {means}')\n",
    "print(f'Calculated stds: {stds}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYSwCw3Rpsx6"
   },
   "source": [
    "Image resizing and image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3c34f65"
   },
   "outputs": [],
   "source": [
    "# set batch size to 32\n",
    "batch_size = 32\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    # Randomly crop the image to obtain an image with an area of 0.08 to 1 of\n",
    "    # the original area and height-to-width ratio between 3/4 and 4/3. Then,\n",
    "    # scale the image to create a new 224 x 224 image\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # Randomly change the brightness, contrast, and saturation\n",
    "    transforms.ColorJitter(brightness=0.4,\n",
    "                                        contrast=0.4,\n",
    "                                        saturation=0.4),\n",
    "    # Add random noise\n",
    "    transforms.ToTensor(),\n",
    "    # Standardize each channel of the image\n",
    "    #transforms.Normalize([0.485, 0.456, 0.406],\n",
    "    #                                 [0.229, 0.224, 0.225])\n",
    "    transforms.Normalize([0.6938, 0.5495, 0.5302],[0.1293, 0.1447, 0.1579])\n",
    "   ])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    # Crop a 224 x 224 square area from the center of the image\n",
    "    #torchvision.transforms.CenterCrop(32),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize([0.485, 0.456, 0.406],\n",
    "    #                                 [0.229, 0.224, 0.225])\n",
    "    transforms.Normalize([0.6938, 0.5495, 0.5302],[0.1293, 0.1447, 0.1579])\n",
    "   ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QeeGwNRet7I6"
   },
   "source": [
    "Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EilX_plpt9L5"
   },
   "outputs": [],
   "source": [
    "data_dir = '/content/drive/My Drive/Deep Learning/ISIC_balanced_split/'\n",
    "\n",
    "train_ds, valid_ds = [datasets.ImageFolder(\n",
    "    os.path.join(data_dir, folder),\n",
    "    transform=transform_train) for folder in ['train', 'valid']]\n",
    "\n",
    "valid_ds, test_ds = [datasets.ImageFolder(\n",
    "    os.path.join(data_dir, folder),\n",
    "    transform=transform_test) for folder in ['valid', 'ISIC2017_test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DoV946Fy6azH"
   },
   "outputs": [],
   "source": [
    "train_iter, train_valid_iter = [torch.utils.data.DataLoader(\n",
    "    dataset, batch_size, shuffle=True, drop_last=True)\n",
    "    for dataset in (train_ds, valid_ds)]\n",
    "\n",
    "valid_iter = torch.utils.data.DataLoader(valid_ds, batch_size, shuffle=False,\n",
    "                                         drop_last=True)\n",
    "\n",
    "test_iter = torch.utils.data.DataLoader(test_ds, batch_size, shuffle=False,\n",
    "                                        drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TN7aGI-S3JHm"
   },
   "source": [
    "Show image - display some of your images for observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7UW0sqDsRxI1"
   },
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    image_min = image.min()\n",
    "    image_max = image.max()\n",
    "    image.clamp_(min = image_min, max = image_max)\n",
    "    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
    "    return image\n",
    "\n",
    "def plot_images(images, labels, classes, normalize = True):\n",
    "\n",
    "    n_images = len(images)\n",
    "\n",
    "    rows = int(np.sqrt(n_images))\n",
    "    cols = int(np.sqrt(n_images))\n",
    "\n",
    "    fig = plt.figure(figsize = (15, 15))\n",
    "\n",
    "    for i in range(rows*cols):\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "\n",
    "        image = images[i]\n",
    "\n",
    "        if normalize:\n",
    "            image = normalize_image(image)\n",
    "\n",
    "        ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "        label = classes[labels[i]]\n",
    "        ax.set_title(label)\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rucCMNrqNsX9",
    "outputId": "4229d04c-8ab9-4937-d274-5fbd0ad594f2"
   },
   "outputs": [],
   "source": [
    "N_IMAGES = 10\n",
    "j=int(len(train_ds)/2) - int(N_IMAGES/2)\n",
    "\n",
    "images, labels = zip(*[(image, label) for image, label in\n",
    "                           [train_ds[i+j] for i in range(N_IMAGES)]])\n",
    "\n",
    "classes = train_ds.classes\n",
    "\n",
    "plot_images(images, labels, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NETRAKM8qW4v"
   },
   "source": [
    "Define the CNN - this example will focus on AlexNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wxq-Q9K9kzBw"
   },
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 3, 2, 1),  # in_channels, out_channels, kernel_size, stride, padding\n",
    "            nn.MaxPool2d(2),  # kernel_size\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 192, 3, padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(192, 384, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, 3, padding=1),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(256 * 2 * 2, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.classifier(h)\n",
    "        return x, h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTbbA3M4q6Y0"
   },
   "source": [
    "HERE you can adjust the number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DiOgETzglDMN",
    "outputId": "c5f28c0c-7179-427a-dd04-7c7310f3f754"
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIM = 2\n",
    "\n",
    "model = AlexNet(OUTPUT_DIM)\n",
    "\n",
    "def initialize_parameters(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight.data, nonlinearity='relu')\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('relu'))\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "model.apply(initialize_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qy7KSZg3uUb8"
   },
   "source": [
    "This is to display the number of trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wrROb1bETFDy",
    "outputId": "765c6930-f265-4125-c3af-2adbe88b86fb"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5yE7GYedACj"
   },
   "source": [
    "Setting the hyperparameters and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ha6oXvmRdDUL"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "CHOSE_LR = 1e-3\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=CHOSE_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sCPodX8Md-58"
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim=True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bpvs2GyNmtT4"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for (x, y) in tqdm(iterator, desc=\"Training\", leave=False):\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred, _ = model(x)\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in tqdm(iterator, desc=\"Evaluating\", leave=False):\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t-PrMgRvekuh"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "93LCuMfKwOXX"
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, iterator, device):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            y_prob = F.softmax(y_pred, dim=-1)\n",
    "\n",
    "            images.append(x.cpu())\n",
    "            labels.append(y.cpu())\n",
    "            probs.append(y_prob.cpu())\n",
    "\n",
    "    images = torch.cat(images, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    probs = torch.cat(probs, dim=0)\n",
    "\n",
    "    return images, labels, probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "c4784f68e5b04a4faa7c7dc45af70351",
      "98889fbe107d4403a439631cdb6c8afd",
      "ca5fe90f0df742e1ad4437ed827c5117",
      "c3c7701039ce4460a748604be4a7666a",
      "a29e83dd1af842f98a38e70375136b6f",
      "d697e6572d3648aeb6b1c44cb19521a3",
      "2943c6671db2415e95d09a7e08060875",
      "1b24b7f57c4041f8900026452f50ad03",
      "90f76171d8e84312811ac4b0789840e3",
      "b46fc052d8ee4feb9e93ca136e9e3510",
      "e09838c46377410ca72538b1e667db99",
      "e6804f778f634a5899cdcebe04e51805",
      "53090ca01c8a4e9bb74bb5b33aa98cc6",
      "23cb167d7fa74081ba0f4a68ed8b5d76",
      "aa4dc29b48e946ab8c88f52ebbf22e2c",
      "5424aaca989b4b1d965067372758fead",
      "734a2027bb7c4dc0b57a7de7486e55c7",
      "83023dd63c18456eadd5a08f697691a0",
      "afe70875ed544ca7b1ce71574dbbfb41",
      "55f2da0564f34286ab1e35a92c2a30c0",
      "0f67a5f1f344473d8b2a3539e74ba439",
      "984d23713d5443478e7523d542566483",
      "5dffc73921ce48a1a27ee68cb548d3fb",
      "70091e4c93ff48b5b9e3eb9716d33951",
      "d1f88bdc762440f7976893b882109712",
      "49403d2c33704e559c1d3799c35d68a5",
      "db0c6b00697142b788663b8d5b78ad01",
      "29b51a5f0ea646ff86af103d26bbe711",
      "73f9e55fbb0f49d086a791ccd537d5f9",
      "ae9144ec1b434e4faca68b99b313b98b",
      "36d77dae0f2f43d09a6fbb4536762fb3",
      "cddfb62b3ece4afe887ef44984ff4a7b",
      "271f7e1c33ea439db4e0b0108d838015",
      "2a5ece093c4b4f228e70958ba62e2c58",
      "77977d94cd86405c949f940ad708d6de",
      "4af4d185056e4838b359e3e7eb013a39",
      "efacefa927e74952b60dac8f14a35872",
      "c3e030fe941d40859da538cdde07b6e1",
      "ddf3aec7adbe400d973a516dfcaef1a2",
      "9bcdcbf3e54e430986983f04a20ff091",
      "ac014660cdc04b4bb16451ed07dcfb61",
      "628fd92f337d46e9b3ad315cf6ee2edf",
      "7ce54dbd7aea4e0f98087b5a660767e5",
      "8f30b3fe103b4b82be50c21d4b824f6c",
      "ebb2da3cde6848dab386d1ec89170a52",
      "f1fe5fc2a39e45fa8506e29593418e61",
      "e008f227b72c4166a91c2cd836815ff2",
      "d408807a050c419db8b2df98f76c5131",
      "a17abe77af1e4e8e8a5473017651059f",
      "46d042f708c24a2db3bb7773930099a4",
      "e1f083708e3d4742837fbbf32fc082e6",
      "c108339b976c47d5b399264f6c241b37",
      "79a2b6f7e99244fc985dcbae23835c13",
      "50283f05d88c47408bb5133ad0489f61",
      "bfd2d25a93b849818bd3bcd776247938",
      "c9648b40b829479b8f48270bcd2e6101",
      "6a485e1f447a47f28cdd6554e05c9638",
      "fe4e0ee6bbb54fb6b5c2b5a733091edb",
      "bc8d08c925ea42459e3412df1dc36595",
      "db610eec65d64c5ca826e50e74bc5d5c",
      "86966fbf827f44fda1fa53b6ff658d6c",
      "dd6026ad77e046cabaa0c54235cc3486",
      "033cf71f0662408bae431328ee5c8a09",
      "2cfa3dc6cd854647974cf760c07572a3",
      "d4876e55a8144cf9b095330ca88043ad",
      "88f22b7dda31408dac6516d31425e012",
      "a04a1c44bdae4c59a2f4113886d21244",
      "4ac94eb649c4420f8433068947da9ed5",
      "9717e6acf4c745378ce60f0cc03518d2",
      "b6c04c35f3224973820b05a8e9116594",
      "759b40b07b7f4414b83a9fe55dfed564",
      "e99c9089013f47c8aba4eb662296cd4f",
      "aa3bb50661454b43a23e41447efffdbf",
      "73225605efed41ad9ff10f810967c34e",
      "ca18ce984318465ab3f01d6a3e65dd3e",
      "54faa0602a3543689d00a087c108560f",
      "2babdf732a7942b4a206dcd6e45eaa57",
      "df0ecad7e4fa49898fbbc672b8f34bbc",
      "7b6f445ad60746b7ac6eb06c2a0aeda2",
      "e319a4720b6b432ab4cca7546b541078",
      "d51188b5fddc4bd2aa409666c6495184",
      "46abf4547d6e4aada2e5b51f52dbdffa",
      "588164fe409b4c0a9ffbb1c14d6583bc",
      "c3b66ba3dc4d4f47b2281e35f92646e3",
      "651f3aba5da64870b28af4dbcef42700",
      "9fc7943fde7444768402dd7a48d059a2",
      "26f11845c7884ae5b9ebb96c61f85c41",
      "425a154ffa774de389505823b647c1b3",
      "ffc59baadbeb4f4f9226bcbf47ba10bf",
      "99f8b52a1fb44842b4fa90fdf16d9f4e",
      "a07072ed7900436488515ed1d110be1f",
      "72c25788cbaa4359b149fd04527c502e",
      "add33615ea4e47879c0905273d73cfcd",
      "a748166d2999479e91b83819d423a826",
      "b8c2d17a11a44caf9c18b6477f0e66ff",
      "30bf150af9b44832840e48f3bee55580",
      "fa3747bafdbc4c3abda4e004158a9741",
      "7df5bcd0dd1a4d1c8ec38b49ae277c19",
      "2e4073895de74d23abdf6f1182ff207d",
      "4e9cf5352b404cbe985b85e604afe0e3",
      "895507cfbef74f7bb8b3677a5c05fbee",
      "b4ccf49024c34f049c549e4a3ed6ded7",
      "70a937ad42ec40cab663cd9e0244bb65",
      "fcbf46a18c604f78971736dc97d1d334",
      "ad09ec7a1c81412b92aaf312e80c87dd",
      "d453ab043e12424aaeea8abc5c13e044",
      "8b0532c8aa024046b36899bb7f5b9886",
      "bfe2a6e5c7a641a9af9656ec2eea8105",
      "331f38fef20d4d08a89dbceb78638982",
      "15876b4e3930456b9da6570b04d37cbf",
      "009096fc9d494a648fbdc51ca46974c5",
      "7505700a4436404bad5774538bdd80ec",
      "094ef9a567da48fe98a2c5a6fb17b8f4",
      "c9cade175bd64eb5aaf68905517e7e36",
      "cfd4f6dc9e69479d968985a8a427b471",
      "e939d534c8d54b7ebbfdeeed1d226703",
      "ff024171f39541469cdd67178f56999d",
      "e5aa689263af4606a8ba0aec242e0374",
      "3ca74cb4d3754b1386b23af4dba087e7",
      "5ed7b60fecd242c9be1b7f22b4969c76",
      "086369f772a54a2b83a0e8d7b7e856b0",
      "6584758847624a569da649d47ca7e4d6",
      "4c4c0ceb6cbc4bccac98bb009865ef0b",
      "9adff1033dd243e5bfa922db4ff7382a",
      "e5b21ceec1f44bea9e638f7b2fc5ef3b",
      "7e3c5630f416416ebaf03f2ecde1568e",
      "c95d706772d24817946af5fa9722bd58",
      "cfdf312e4d3b4297b431de4aca13ccbb",
      "be909fda0425449c849d33333ff99fdd",
      "15cb69d9731443de983cc6fbf6137383",
      "56de0313b801493f839bccff92f57e2f",
      "8769781ee6744fd485c23023b7c61a76",
      "af5ac3ada94447a9ae73b5c28ee9879a",
      "45052ff488b74862a58c9c2848bec3f4",
      "9bf8bbec69414975939e6eee99351213",
      "80250171b32d4a429f3e2a19bb7ac1d4",
      "aeef316e98cc464881f5ede9061885ce",
      "60185fe2276041a79864017625543e33",
      "2cc0df4c96644116809d0131d0624de7",
      "80712d7c6a0345148aa71f1a3735a3ea",
      "824679980b294dbc9031e03605b23175",
      "11b37f86d26f43dcbb546d6bf4338569",
      "218ac4425b8543309b592160b9702c2b",
      "8ab19a89c9f041f0b485d918513ed149",
      "93618b04ced742df81b488a67ed64904",
      "417e99139aab4b77bbde0ab1305cd843",
      "fc946e797f014c0596ebde2478d4c5b0",
      "84654c22ade9437c9d896cf49873673a",
      "dae8b650f3e84d17ab50decb15261569",
      "19febe2d59674a1ba3439f7c1c2280aa",
      "1d4e369bfa7a459f8ac0ee135c1cdb20",
      "76f58412f8b54ca8882026d903345510",
      "97d9f9eeb74d409bb34d25b758f7f1ac",
      "f7e0e0f6eab54ccc89b7faceded7e262",
      "1e598fbe23224e18b1432a87c7a37eaa",
      "9eade318d61547ee91de3d41c88f04d4",
      "56f3759c007f4e5fa4dd669aba5bb4d5",
      "b3de6cefcdbe4a9d9cf8e045e0560dc5",
      "e30db617b98843b1add6439bfcdef961",
      "2ed4adf5cff34f8f962f8020710ad0df",
      "a33538f299f54e839130b9e15d6d235f",
      "0ed37f9b36e84c28a4e8f868db810779",
      "959c5a4b7dff46f2afa1eeb248acb9f4",
      "dec6390b30384105837a7a869652e398",
      "32bf761f8e144a56898dfa595be9d7e2",
      "3b5504e89ecb4a3c941003447a27fc44",
      "0949cda176f84d44928c5a326b2dbdc4",
      "a4847a3e1c604a1f874761e604e50bdd",
      "207a16dc9f754eb79800dff715396c14",
      "7e4c08a3f3624c2ca0ddafc8c3ba1edb",
      "180401c15c6649d5b4114d288936bcca",
      "dec3d09567034d9591df4fe22fa5047a",
      "ed5b9549123e476b80b27a1c11a0f2bb",
      "fbbbdd16e02244828eedbae271852ce5",
      "85200ae12e5a416a885519400078fd65",
      "a4212be6df1e498c8f8a36a9780d7e80",
      "462b6a97d59c49a7826aa35225dfc316",
      "50530de8667b403da107e55007fc9f61",
      "64683d507dc34d6c90497e8b459bf292",
      "ee5b9eb1af2443bdbb70b3f6101b06c9",
      "2e04525726b34093a08f0980c53f3815",
      "2220248424a64e6aa94171d427a48e78",
      "1dfea553d3ed412db2d62ad59beb9ce7",
      "a9ba4ea9c470445aac47ac4dc11bf4bc",
      "ed2885c807e74eb3ad4a64e6510fe77a",
      "f50849c61b09467d87226d9789a3849e",
      "c90e1db7bdd9463aaa8ee577c79f72f2",
      "e8b92f3d419447689e14c6c71228510f",
      "4998c894e59d4148b989d0ec642bb03f",
      "57b4644948ad43bfa8cc9472bc3beb21",
      "d27d5390e0624308a09a0d866819cfa8",
      "dc0c4d1cd8734eadad9972f3c7787c73",
      "3b8c87a8783c419fa2f8ddf400a8d278",
      "35cdbf7b785b4c0b8bf590fa8f7feb80",
      "bc21eaf3d1864d8486242ae770143cd3",
      "4d0970afb7be4a4cad767a2240a5c4fb",
      "1931e8e5d4cc4857be3a96b5afc58fd9",
      "455621802167437d99eca3e43f382fcf",
      "5653ef230065473487cfb892d6fbdc4f",
      "aa7bd15ad2e04f17bfdef1102acd8501",
      "d4a8fbc7a4054eb9bf2e3431c5d63cf7",
      "ee15821774964f8eba94d52f9bc2f21a",
      "45038ec2f1894145977e419e713a6c85",
      "7f6d2bf3526e43c4a8f90a7c05e8b2a5",
      "86daea49c1814faab0f81a067a48c0c0",
      "4295ef509ef5429080f3871cab418e2c",
      "4d6b3cd8f92a435794ba9ff5123f1317",
      "492a33c2c380410f98b4bc106af902bd",
      "2961c0ef298b41d388a174f2cfe07a78",
      "ce7f4bde33c44de6bdba74d85748b6cd",
      "f1a56004ec3d4e08980d8ab98b867a8b",
      "cbcadcf98d90443d84667bca59bd849e",
      "84644903bed44256a240944abc361992",
      "452626bdb34e4ddb882b469482a3bbd0",
      "20ec3a0a3f5f464690d292ab6c3ab445",
      "24b5fe5a40164bb79506a1f451b55da9",
      "c8e6cafea51542a9861c4811886fb73a",
      "d7ac364105714052bb98af4602f42c00",
      "de91ac145aad4f48bef315a4932a5d54",
      "56fa7f5bc28f4ffebe13a3470cf666b1",
      "7f7f7b97cf484a629e12d9257f9e7905",
      "3d6f1b643be742eb98195bb0daf8efc7",
      "a747e7c10a7143e483a3e643ae296e89",
      "6772453740c248d6a417cf4038880037",
      "b1331eed15134447ae5fbbb5488a4a06",
      "869d6371659541ab9f8f6595f38ac68a",
      "55bedf1d4fe64503b00e1a8d8e9b3b65",
      "9eb3a22014da4e7b9cd97b191383827a",
      "89c7b46b215044dca7cb023050a48a46",
      "3cbaf38601264e0baa14d2e4d5d6ba39",
      "8c4e3fdd2f2d4e3dacc6bfabd095c4f0",
      "6256eb45749945c7baca4af55f11cdf2",
      "be99b6f8a6d2400fa5336521b865a1a6",
      "230b91f6fa174366915b83fcae1a04b7",
      "ffabe118b84b4042816e9e9226350dad",
      "facd1ea2eb0e470a9c40313e08c2ba8d",
      "5281bad809be4d7aa27de53347c735d9",
      "33b969daac274b1b845ad2586ebee8be",
      "845b0e852d724da89ef113ebeab05b29",
      "fc9d092426a54505aaa5e01d45a9b53a",
      "a7c89aabd6834585843e3849ec314e0b",
      "d874393d36ec4ed78a238e12775bceab",
      "47a91335b28b4bca8e9f79668bfef675",
      "3e7a1dd4cf024c8e86410f20c2a921f3",
      "e8427680897845098b1542e65854cb59",
      "86f16da4b3e148918903aeb8507f7232",
      "ec081f40677a48d29806a2b761eb9dad",
      "9a3e7c07caf248a59e5f38b871528a45",
      "0f21047c3d734212a00592524f15e473",
      "c572deca7fd54906bd42d8e45050420d",
      "c71fc44a5ab34d7e838b24dce93e9a48",
      "a06ede0ea92847ed82dbd8fbd3e0dc81",
      "9e81954ead314baaa913a7cf77a56773",
      "4ded2e5f91ce4ad08fb6340c0b80db49",
      "e257b5f87bc44232a9dee82b0028df2e",
      "a5a280e47e0444c7a75cfaac001c1808",
      "c896a72f5ff14e38ac079345c187ebcd",
      "3b73f4c954fc4ee79057496f120588d0",
      "6799c67f0b5d4f1587a964b38748dd1f",
      "f3378a14dbae432e8e5cebb5857b4772",
      "7766dc32e5034ee781cb05d5b6556a8a",
      "93d1d67a9e4744b0bde9aa3a2be8e8f6",
      "f49455f880ab4089bd912686df54e8c3",
      "1dfbbb575f674620b387df8c2f00798a",
      "6c2d0661d31e4df382558ea9a85912aa",
      "5012c51c7e204b3697c7362575f19cc2",
      "a846ada64b4c467fa11af83e6c901c78",
      "90efd756318645c39853fd69f4b8fc8b",
      "37cdb32dd8d3459b8e4ab6460b9f2de5",
      "b6e148d5b62d4c7aba9f9334143a6145",
      "2fe754e4ae6b4965939027d09f0c3999",
      "01c75b3083154259809bd92fb54f1eec",
      "eb6d4a11358146baa0f2094074f75f0a",
      "23d379ece0854247ac5edc8da2dd0240",
      "c72302f6a31e44ba8947cb05413c90ea",
      "eac3474bf9884e7bbd5ae39c26557d87",
      "a35d42a85a6148209c20bbf9f0f807dc",
      "f4b634e4273d40e080bdefddd18bac75",
      "26d315c1370e4391b744dc4ddced150f",
      "cf70aa4f40124d68bd10ab70576b10db",
      "a2db6ebb26104d53a10716d69ff01f8c",
      "f1441b3469bd494ab9026681e92b3c63",
      "bc9288eab9d3406f8ef5aa9c877f9858",
      "fc21a14a1ac948468720cde52c38376f",
      "d52a78adb2304ca3bf1601a751755a72",
      "5dadfd5f593f40efa7ef302d91b5fdec",
      "53f8d29e98184414a60f1db7f0c4dfd0",
      "14df9d5b861d4b08b7bebf6d30bd867f",
      "60ec06b9e3244bffb299557609d36ab2",
      "e9e1154d7c2f48c99c8b10a367746eb9",
      "41f7d6816c4b4a95ac710e74d0ec98e9",
      "de61738e1322435493fca941f2358783",
      "52dcd50c79b946baba2bea575cfa500b",
      "62cb436851aa4294bcfc5b473cc8d773",
      "be6ed0d217374e38908cc1ca131b683e",
      "3d469373e6b14693a3ffbedf2caf8514",
      "c93b823b979241b287ae95081351303d",
      "791b3bd7fe56485b947f45caba2588ee",
      "bd1bdecfe9fe46c2b33bfea704edc833",
      "199b782ced9e40f0bfb4b78c8163ca81",
      "3c2603b24d6d49598508e76b758a0f31",
      "b35cea7cd2ff486f805fcdad65c74980",
      "c217e83d6a674338ad993cdcc3f186ab",
      "2e8c557b55d54b4db8a6960b14d1a684",
      "040f73a41b404ed3b21f5a97c97a3e94",
      "f9ac5c8820f74d53a887adc3a1bd0520",
      "025dada28ed74553a6f36f9aa5010000",
      "93e4b3517d2842b08bebfdb300e1f068",
      "0c97b85d12d447e1994e4f5abdd59f56",
      "21fa35fb8f554201b3465cc2dc791da8",
      "e1a761743faf43719ad9f3715ece5e9b",
      "19d6c3be94a5474b8d2995223eadee91",
      "66b93175efe9426fa7612b546c356fa5",
      "082edfe84ed2412188e01f15626fa985",
      "149541ab2d524403891c1cbd4a4ca828",
      "e8e0334d425e4c568256e46e2ae4c57a",
      "70dd42c9651944798f21321d9cbe4626",
      "97fcaf625eac4682a3cfa77fa237aaa3",
      "8cb397a0d4e34a5d8ee76c84e832f002",
      "2b84ae8646d341d39dd3c347c69206aa",
      "df6b222e87cb4c679f283c905d082ef1",
      "c5144f0af8d94986b4bff539c063be1f",
      "8538d8e534b24109aac0b56015271c52",
      "74fb074f68ca4eadbfba32bd6b009fd2",
      "a5338814a36e4e8693d1698bc84e2b75",
      "579c1bb6d75f47aaad42a2277e9995a2",
      "3931b9e1a5d44e838e5cbf14f731a9e5",
      "a45e7ba7df034bee81cf5b1da58d9b5b",
      "f9cc2e0c5b11408da902657f93aba267",
      "3b968d4c6ed64f15ba27e9913e9f97f7",
      "9ef777bde39443b4a49437ce77d415bf",
      "fe83644ed7da4a88b93b6807dc555296",
      "31be57a8dbf6420a811bfbc8dcfa4713",
      "488caef90a2246468102f62840d3b531",
      "8b0199519531415ca6e17b0cc05e7d85",
      "d102e095507d4c31860ef4e88a95fcef",
      "f1e0209620924c2f89c35180d94a9483",
      "6908c8cf4b7949669c87ba46e1f90c81",
      "abea03a1331a45559dcfa31c867eb678",
      "dd8d479e4ece44deb012fa4fee8a43c4",
      "75477880fc564b998888e16aad20a862",
      "5f525e3302174e0b8103a9ed0db5b243",
      "31bd60b35746457b83166d153d023575",
      "1c91ac9ae89640e3a4d4783bf5b84eed",
      "ccd95d9de1fe484ea519dccd7444ba25",
      "363c2b27005f44bf93626f8fd85f8732",
      "6d2c3bbabd9a4a5c99cf94a8c479debf",
      "952a780674c2432794293b59674c49b8",
      "74f89f2e63cb4fc680092bfcd38098d7",
      "fac1ad9aa5904c3dac2ade54305f7321",
      "7449a6b80ab141af84b3f0e5198b7a36",
      "6973bf92c80e42498d352a0cbd63eef9",
      "50266305921444fb8eaac26454ca5369",
      "83d9719a168a41ffa756242ce01b78ea",
      "0883ba595d624910b0acfcc8d8bf12ff",
      "92d7f6e2970440b3bd84fb8ab5c8b893",
      "b8a15724a24544f0a550cbaec2657cc3",
      "60c0a3823ecd4236b0c38c4961e1e509",
      "2025289b5ba24dea91f1e363c1a6cbc6",
      "4ec501eecdd242d783815aa77ed2f83a",
      "914c9f48013b47aa9b08e36a8b22a296",
      "972e04730aa3418dac28878b61365710",
      "b288c84aac2449cfaa42543482c3b174",
      "0c7c12f308464135a9bf107313cb52fd",
      "b6122dbb700047909bb7d2417eeb4882",
      "7c7a353b11e24240831312cfcd315710",
      "34c9ce3728b24cbaba5a33d61fb4b8c1",
      "9b0dde1ef4c74199818ea2bf6a00d0d0",
      "72d355895a6c4f27a1efcaae6b2f11ee",
      "531a680f3661445382021833b7bc4ea1",
      "aa34e39e8a69449484b124bd898ca1ee",
      "44f313eb09d24a1f8e4a0fdc3b86518a",
      "a50817132ddb41b680b3d0d00d284f2e",
      "172e2ac5c3524b24919b3ab2950a6aad",
      "9da7b7c319494723ab0d0ace86b41340",
      "63dc3d30309a47fb98b574a2cba5fdc8",
      "faf100d5a3954bd1badacbb9728a5f20",
      "f63968cd6efd4afaba1476502df87aa4",
      "223e804d67c34ae9a6b1bb24834062d2",
      "51eed22021074eacb85cbe016a51fb12",
      "8ec6dd36ce6d48f58f491fdcbeec590c",
      "edf10abc90d8415aa43bf80848d9ddb5",
      "15d7c147948b4f9ca13e73a6941a8a02",
      "b458a0618eb241ad94eb5ed6e647bada",
      "842f3bff6c584c6f8b1f1ca50eb608a8"
     ]
    },
    "id": "jPFaZa0Am-aN",
    "outputId": "f072d74a-bf2b-47db-8d36-e13a427d0596"
   },
   "outputs": [],
   "source": [
    "!pip install early-stopping-pytorch\n",
    "from early_stopping_pytorch import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(patience=7, verbose=True)\n",
    "\n",
    "EPOCHS = 20 # You may need to run longer to get better results. Lab example is for demo only\n",
    "\n",
    "# keeping-track-of-losses\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in trange(EPOCHS, desc=\"Epochs\"):\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "\n",
    "    train_loss, train_acc = train(model, train_iter, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iter, criterion, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best-model.pt')\n",
    "\n",
    "    early_stopping(valid_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSaOuT-gv0wc"
   },
   "source": [
    "Example code to plot losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "7su0E10QsoLG",
    "outputId": "a36b356c-7d2b-43db-f799-e82ff917c768"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLg-UGiOztuD"
   },
   "source": [
    "Loading the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rm0fXD2ltfoH",
    "outputId": "db552844-6bb4-4dbd-893d-45651d14af4b"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best-model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pq_2cz0xgwtm"
   },
   "outputs": [],
   "source": [
    "images, labels, probs = get_predictions(model, test_iter, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W1S4ee_3g_Oy"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('/content/drive/My Drive/Deep Learning/ISIC_balanced_split/ISIC2017_Test_GroundTruth.csv')\n",
    "y_test = np.array(test.drop(['id'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 925
    },
    "id": "H6utF06dhZ6o",
    "outputId": "02f04b4b-e9c7-4725-e019-ba87932bbbbe"
   },
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "import numpy as np\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "#change to OneVsOneClassifier for generalized AUC\n",
    "#from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "#from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "n_classes=2\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], probs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), probs.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[1], tpr[1], color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[0], tpr[0], color='green', lw=lw,\n",
    "         label='ROC curve of Melanoma (area = {1:0.2f})'\n",
    "         ''.format(0, roc_auc[0]))\n",
    "\n",
    "plt.plot(fpr[1], tpr[1], color='darkorange', lw=lw,\n",
    "         label='ROC curve of Other (area = {1:0.2f})'\n",
    "         ''.format(1, roc_auc[1]))\n",
    "\n",
    "# if you need more classes\n",
    "# plt.plot(fpr[2], tpr[2], color='red', lw=lw,\n",
    "#          label='ROC curve of third class (area = {1:0.2f})'\n",
    "#          ''.format(1, roc_auc[2]))\n",
    "\n",
    "# plt.plot(fpr[3], tpr[3], color='cornflowerblue', lw=lw,\n",
    "#          label='ROC curve of fourth class (area = {1:0.2f})'\n",
    "#          ''.format(1, roc_auc[3]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curves of Proposed Method')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Ly7GDpRritFY",
    "outputId": "85865c89-2fd9-4694-86bc-f950241c8506"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from matplotlib.colors import Normalize\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "pred_class = np.argmax(probs,axis=1)\n",
    "true_class = np.argmax(y_test, axis=1)\n",
    "\n",
    "cm=confusion_matrix(true_class, pred_class)\n",
    "class_names = unique_labels(true_class, pred_class)\n",
    "print(cm)\n",
    "print(class_names)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "C = cm\n",
    "divisor = np.zeros((2,2))\n",
    "divisor[0][:] = 117\n",
    "divisor[1][:] = 483\n",
    "cm_normalised=np.divide(cm, divisor)\n",
    "print(np.transpose(C.sum(axis=1)))\n",
    "print(divisor)\n",
    "cm_normalised = np.round(cm_normalised, 2)\n",
    "disp = ConfusionMatrixDisplay(cm_normalised, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Za6ZoHvNoFak",
    "outputId": "e0ecd7af-6f0b-4b30-8c57-c711ec35b1a9"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "pred_class = np.argmax(probs, axis=1)\n",
    "true_class = np.argmax(y_test, axis=1)\n",
    "\n",
    "precision = precision_score(true_class, pred_class, average='weighted')\n",
    "recall = recall_score(true_class, pred_class, average='weighted')\n",
    "f1 = f1_score(true_class, pred_class, average='weighted')\n",
    "\n",
    "print(f\"Precision (Weighted): {precision:.2f}\")\n",
    "print(f\"Recall (Weighted): {recall:.2f}\")\n",
    "print(f\"F1-score (Weighted): {f1:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FMdlbRvPNR9Z",
    "outputId": "d2a920ee-83f8-4aa4-c62d-d587b6e2d0ab"
   },
   "outputs": [],
   "source": [
    "TP = np.diag(cm)\n",
    "FP = cm.sum(axis=0) - TP\n",
    "FN = cm.sum(axis=1) - TP\n",
    "\n",
    "precision_per_class = TP / (TP + FP)\n",
    "recall_per_class = TP / (TP + FN)\n",
    "f1_per_class = 2 * (precision_per_class * recall_per_class) / (precision_per_class + recall_per_class)\n",
    "\n",
    "weights = cm.sum(axis=1) / cm.sum()\n",
    "precision_weighted = np.sum(precision_per_class * weights)\n",
    "recall_weighted = np.sum(recall_per_class * weights)\n",
    "f1_weighted = np.sum(f1_per_class * weights)\n",
    "\n",
    "\n",
    "print(f\"Precision (Weighted): {precision_weighted:.2f}\")\n",
    "print(f\"Recall (Weighted): {recall_weighted:.2f}\")\n",
    "print(f\"F1-score (Weighted): {f1_weighted:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92eqch_21Og1"
   },
   "source": [
    "This is optional visualisation for those who are interested in interpreting their results. MIT License: Copyright (c) 2018 Ben Trevett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1YiQh8awkPp3"
   },
   "outputs": [],
   "source": [
    "def plot_filtered_images(images, filters, n_filters=None, normalize=True):\n",
    "\n",
    "    images = torch.cat([i.unsqueeze(0) for i in images], dim=0).cpu()\n",
    "    filters = filters.cpu()\n",
    "\n",
    "    if n_filters is not None:\n",
    "        filters = filters[:n_filters]\n",
    "\n",
    "    n_images = images.shape[0]\n",
    "    n_filters = filters.shape[0]\n",
    "\n",
    "    filtered_images = F.conv2d(images, filters)\n",
    "\n",
    "    fig = plt.figure(figsize=(30, 30))\n",
    "\n",
    "    for i in range(n_images):\n",
    "\n",
    "        image = images[i]\n",
    "\n",
    "        if normalize:\n",
    "            image = normalize_image(image)\n",
    "\n",
    "        ax = fig.add_subplot(n_images, n_filters+1, i+1+(i*n_filters))\n",
    "        ax.imshow(image.permute(1, 2, 0).numpy())\n",
    "        ax.set_title('Original')\n",
    "        ax.axis('off')\n",
    "\n",
    "        for j in range(n_filters):\n",
    "            image = filtered_images[i][j]\n",
    "\n",
    "            if normalize:\n",
    "                image = normalize_image(image)\n",
    "\n",
    "            ax = fig.add_subplot(n_images, n_filters+1, i+1+(i*n_filters)+j+1)\n",
    "            ax.imshow(image.numpy(), cmap='bone')\n",
    "            ax.set_title(f'Filter {j+1}')\n",
    "            ax.axis('off')\n",
    "\n",
    "    fig.subplots_adjust(hspace=-0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0yvqclEk6cuk",
    "outputId": "0fc4e90a-cbda-4a60-abe5-9a7f6a6a140d"
   },
   "outputs": [],
   "source": [
    "N_IMAGES = 5\n",
    "N_FILTERS = 7\n",
    "\n",
    "images = [image for image, label in [test_ds[i] for i in range(N_IMAGES)]]\n",
    "filters = model.features[0].weight.data\n",
    "\n",
    "plot_filtered_images(images, filters, N_FILTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q-1uV_5wkWWt"
   },
   "outputs": [],
   "source": [
    "def plot_filters(filters, normalize = True):\n",
    "\n",
    "    filters = filters.cpu()\n",
    "\n",
    "    n_filters = filters.shape[0]\n",
    "\n",
    "    rows = int(np.sqrt(n_filters))\n",
    "    cols = int(np.sqrt(n_filters))\n",
    "\n",
    "    fig = plt.figure(figsize = (30, 15))\n",
    "\n",
    "    for i in range(rows*cols):\n",
    "\n",
    "        image = filters[i]\n",
    "\n",
    "        if normalize:\n",
    "            image = normalize_image(image)\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "        ax.imshow(image.permute(1, 2, 0))\n",
    "        ax.axis('off')\n",
    "\n",
    "    fig.subplots_adjust(wspace = -0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DTGOxF94kgBE",
    "outputId": "fc75518f-bd15-4e2c-bc53-10639d303614"
   },
   "outputs": [],
   "source": [
    "plot_filters(filters)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
