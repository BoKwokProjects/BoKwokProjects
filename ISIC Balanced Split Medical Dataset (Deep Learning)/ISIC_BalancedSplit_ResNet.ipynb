{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39882194"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "from collections import namedtuple\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import collections\n",
    "import math\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6061aGw4pM0w"
   },
   "source": [
    "If you want the result to be reproducible, you will need to set the seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QrPC2sxvRkvX"
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSV0OKw4pY14"
   },
   "source": [
    "Mount to Google drive and unpack your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-h6147Klo6y",
    "outputId": "486b9ac7-8256-4fc7-e570-802fc2a905a9"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4B7PKK1Y1FYV"
   },
   "outputs": [],
   "source": [
    "# Unpack the dataset zip file\n",
    "shutil.unpack_archive(\"/content/drive/MyDrive/Deep Learning/ISIC_balanced_split.zip\", \"/content/drive/MyDrive/Deep Learning/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RIKPVr-XyUL6"
   },
   "source": [
    "Run calculation on mean and standard deviation of my train dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjv-NBDLp4No"
   },
   "source": [
    "This is an additional code to check the mean and standard deviation of your dataset - you can then use it to replace the values in transforms.Normalize to improve your work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nbsqpyy1gFze",
    "outputId": "4e12b84f-27e2-4d9e-d440-397052277586"
   },
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(root = '/content/drive/My Drive/Deep Learning/ISIC_balanced_split/train/',\n",
    "                                  transform = transforms.ToTensor())\n",
    "\n",
    "means = torch.zeros(3)\n",
    "stds = torch.zeros(3)\n",
    "\n",
    "for img, label in train_data:\n",
    "    means += torch.mean(img, dim = (1,2))\n",
    "    stds += torch.std(img, dim = (1,2))\n",
    "\n",
    "means /= len(train_data)\n",
    "stds /= len(train_data)\n",
    "\n",
    "print(f'Calculated means: {means}')\n",
    "print(f'Calculated stds: {stds}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYSwCw3Rpsx6"
   },
   "source": [
    "Image resizing and image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3c34f65"
   },
   "outputs": [],
   "source": [
    "# set batch size to 32\n",
    "batch_size = 32\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    # Randomly crop the image to obtain an image with an area of 0.08 to 1 of\n",
    "    # the original area and height-to-width ratio between 3/4 and 4/3. Then,\n",
    "    # scale the image to create a new 224 x 224 image\n",
    "    transforms.Resize((32,32)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # Randomly change the brightness, contrast, and saturation\n",
    "    transforms.ColorJitter(brightness=0.4,\n",
    "                                       contrast=0.4,\n",
    "                                       saturation=0.4),\n",
    "    # Add random noise\n",
    "    transforms.ToTensor(),\n",
    "    # Standardize each channel of the image\n",
    "    #transforms.Normalize([0.485, 0.456, 0.406],\n",
    "    #                                 [0.229, 0.224, 0.225])\n",
    "    transforms.Normalize([0.6938, 0.5495, 0.5302],[0.1293, 0.1447, 0.1579])\n",
    "   ])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    # Crop a 224 x 224 square area from the center of the image\n",
    "    #torchvision.transforms.CenterCrop(32),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize([0.485, 0.456, 0.406],\n",
    "    #                                 [0.229, 0.224, 0.225])\n",
    "    transforms.Normalize([0.6938, 0.5495, 0.5302],[0.1293, 0.1447, 0.1579])\n",
    "   ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QeeGwNRet7I6"
   },
   "source": [
    "Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EilX_plpt9L5"
   },
   "outputs": [],
   "source": [
    "data_dir = '/content/drive/My Drive/Deep Learning/ISIC_balanced_split/'\n",
    "\n",
    "train_ds, valid_ds = [datasets.ImageFolder(\n",
    "    os.path.join(data_dir, folder),\n",
    "    transform=transform_train) for folder in ['train', 'valid']]\n",
    "\n",
    "valid_ds, test_ds = [datasets.ImageFolder(\n",
    "    os.path.join(data_dir, folder),\n",
    "    transform=transform_test) for folder in ['valid', 'ISIC2017_test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DoV946Fy6azH"
   },
   "outputs": [],
   "source": [
    "train_iter, train_valid_iter = [torch.utils.data.DataLoader(\n",
    "    dataset, batch_size, shuffle=True, drop_last=True)\n",
    "    for dataset in (train_ds, valid_ds)]\n",
    "\n",
    "valid_iter = torch.utils.data.DataLoader(valid_ds, batch_size, shuffle=False,\n",
    "                                         drop_last=True)\n",
    "\n",
    "test_iter = torch.utils.data.DataLoader(test_ds, batch_size, shuffle=False,\n",
    "                                        drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TN7aGI-S3JHm"
   },
   "source": [
    "Show image - display some of your images for observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7UW0sqDsRxI1"
   },
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    image_min = image.min()\n",
    "    image_max = image.max()\n",
    "    image.clamp_(min = image_min, max = image_max)\n",
    "    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
    "    return image\n",
    "\n",
    "def plot_images(images, labels, classes, normalize = True):\n",
    "\n",
    "    n_images = len(images)\n",
    "\n",
    "    rows = int(np.sqrt(n_images))\n",
    "    cols = int(np.sqrt(n_images))\n",
    "\n",
    "    fig = plt.figure(figsize = (15, 15))\n",
    "\n",
    "    for i in range(rows*cols):\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "\n",
    "        image = images[i]\n",
    "\n",
    "        if normalize:\n",
    "            image = normalize_image(image)\n",
    "\n",
    "        ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "        label = classes[labels[i]]\n",
    "        ax.set_title(label)\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rucCMNrqNsX9",
    "outputId": "6b87ccf4-0e49-4af8-fe00-2715e53a8e7b"
   },
   "outputs": [],
   "source": [
    "N_IMAGES = 10\n",
    "j=int(len(train_ds)/2) - int(N_IMAGES/2)\n",
    "\n",
    "images, labels = zip(*[(image, label) for image, label in\n",
    "                           [train_ds[i+j] for i in range(N_IMAGES)]])\n",
    "\n",
    "classes = train_ds.classes\n",
    "\n",
    "plot_images(images, labels, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NETRAKM8qW4v"
   },
   "source": [
    "Define the CNN - this example will focus on AlexNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wxq-Q9K9kzBw"
   },
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from typing import Any, Callable, List, Optional, Type, Union\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "# from project.utils import _log_api_usage_once\n",
    "# from project.models._api import register_model, Weights, WeightsEnum\n",
    "\n",
    "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
    "\n",
    "def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=dilation, groups=groups, bias=False, dilation=dilation,)\n",
    "\n",
    "\n",
    "\n",
    "class BottleNeck(nn.Module):\n",
    "\n",
    "    expansion: int = 4\n",
    "    def __init__(self, inplanes: int, planes: int, stride: int = 1, downsample: Optional[nn.Module]= None, groups: int= 1, base_width: int = 64, dilation:int = 1, norm_layer: Optional[Callable[..., nn.Module]] = None,\n",
    "                 )-> None:\n",
    "\n",
    "        super().__init__()\n",
    "        if norm_layer is None:\n",
    "          norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.0))*groups\n",
    "\n",
    "\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "\n",
    "\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        block: BottleNeck,\n",
    "        layers: List[int],\n",
    "        num_classes: int = 1000,\n",
    "        zero_init_residual: bool = False,\n",
    "        groups: int = 1,\n",
    "        width_per_group: int = 64,\n",
    "        replace_stride_with_dilation: Optional[List[bool]] = None,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = None,)-> None:\n",
    "        super().__init__()\n",
    "        # _log_api_usage_once(self)\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = norm_layer(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2, dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2, dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2, dilate=replace_stride_with_dilation[2])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, BottleNeck) and m.bn3.weight is not None:\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "\n",
    "    def _make_layer(self, block: BottleNeck, planes: int, blocks: int, stride: int = 1, dilate: bool = False,) -> nn.Sequential:\n",
    "\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                norm_layer(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(\n",
    "            block(\n",
    "                self.inplanes, planes, stride, downsample, self.groups, self.base_width, previous_dilation, norm_layer\n",
    "            )\n",
    "        )\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups, base_width=self.base_width, dilation=self.dilation, norm_layer=norm_layer,))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTbbA3M4q6Y0"
   },
   "source": [
    "HERE you can adjust the number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DiOgETzglDMN",
    "outputId": "59e99ec7-2d53-41aa-e3b0-f6bf7e14f617"
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIM = 2\n",
    "\n",
    "model = ResNet(block = BottleNeck, layers = [3, 4, 6, 3], num_classes = OUTPUT_DIM)\n",
    "\n",
    "def initialize_parameters(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight.data, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "          nn.init.constant_(m.bias.data, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('relu'))\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "model.apply(initialize_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qy7KSZg3uUb8"
   },
   "source": [
    "This is to display the number of trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wrROb1bETFDy",
    "outputId": "589796d2-1aab-4b3a-cf67-cf64096e211f"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5yE7GYedACj"
   },
   "source": [
    "Setting the hyperparameters and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ha6oXvmRdDUL"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "CHOSE_LR = 1e-3\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=CHOSE_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sCPodX8Md-58"
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim=True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bpvs2GyNmtT4"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for (x, y) in tqdm(iterator, desc=\"Training\", leave=False):\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(x)\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in tqdm(iterator, desc=\"Evaluating\", leave=False):\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t-PrMgRvekuh"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "93LCuMfKwOXX"
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, iterator, device):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "\n",
    "            y_pred = model(x)\n",
    "\n",
    "            y_prob = F.softmax(y_pred, dim=-1)\n",
    "\n",
    "            images.append(x.cpu())\n",
    "            labels.append(y.cpu())\n",
    "            probs.append(y_prob.cpu())\n",
    "\n",
    "    images = torch.cat(images, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    probs = torch.cat(probs, dim=0)\n",
    "\n",
    "    return images, labels, probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "4f28835c724c498682a084f558af6d11",
      "0296dcec1e5f423c887fe3fd00e201ba",
      "0842ff0410374b81a853ba3b89f1cb73",
      "3e1787d95e1d4159b7a4b23ed80408e1",
      "2f78c4aa8c884d1f9e474e90fa708534",
      "be47435d335449aeac124a47a0f2ef7b",
      "eeb13602878d485a8cd30c20d2905bb9",
      "2222197b9bcf49cfa1dbb89fcb32ff23",
      "bf58b8d803eb4a36a5dcaf6cad01c6af",
      "1abeceef0faf43a2a98f27ff885f4d12",
      "26a413d277e648afab6a32c8158dca61",
      "6645a3689f6b4c438c7681921185d0ba",
      "f2a4e18bd0244ef2b42ae45f2b2381aa",
      "d928b2b5122941ccb10e1d277716997f",
      "39a5343febd0493eaf7405c9c8ca2406",
      "beb38a23fc3d4d7f8b0275e90095d194",
      "8a9360af836e4741892c5736ef0e80de",
      "4b9f103b71394a939dc806b43bbcb9ce",
      "dc0bd5a0fd5f4f67a860993ca327d6e6",
      "6b0a4f4a81bc4cd3bb5de89ebc7f7303",
      "d5908472b4cb4cebb7e79d89c48e5ad1",
      "f517ebcaf549462f85ea4c0e02f4e918",
      "68ce2973dae242deb36cc6cba2d83ad5",
      "5b2d5ffdeb084f8bbd89f6b9ad914141",
      "8b454563c3dc44949f813baab6bcd81e",
      "2216d14accad4e3ea10ca1c0bc7788f6",
      "0f347c4584554d8bb469bdadb4e6a0b9",
      "fdc3377f8bb844af80dea6aaf61d0d4c",
      "2e1b8b2647f94f1c8862d59d22279312",
      "74c83302a2d04c9c8e26c1a4d39df7ab",
      "49fe55fed19549e6a519d1ef0cd0d2e9",
      "52e488cc6bae470a830c2df7e3b3eb3b",
      "10f88d41d9a8466fb5e1dab27026e610",
      "5f7e4ce7f2a04625ac97a1344bec21eb",
      "297b8bfaa01d430086e685c892b2a941",
      "3de715fd49f84774b0a15ed17e470b79",
      "c6a41f58a6934ce7804b873cf2fcaf66",
      "4b3ee5a1f9c340dbb8c725bb049ad042",
      "952f3d36216744f1ba3ef1ac6c9c310a",
      "b32fada1395c499bb1ca73e55838f474",
      "7c1013721c4742f7bc2497d3c2ec68ed",
      "caa7884ae0b544af931ef080a3953b2e",
      "0e23912788924f9cab1bcc920aefce9b",
      "ff3837982e8c4ecabfeeb7473c6d610d",
      "d0a3265723984933a139c6a5d21542f3",
      "5b0c798963f24780b5ac7980e97eaa0f",
      "c14bc82df9144fec9b7d2ca76572f1e2",
      "9a163ac80ef9459fb5169b75b230c6d9",
      "899bb90f384848eabcf903fd5c54c8d2",
      "ac76f9c14eec402bbcc3a8bcf3d275dc",
      "4a9a00adf4314d069c3874be8a0f1ce1",
      "02fbeccc3b6a4c258affc87404a54e5f",
      "e609eb673bfe4d1f84926de418f17abe",
      "7143c2173c5d437c8c4e0dd32ec3c616",
      "5c158b275ebe47c696681c7c1f9cd96f",
      "11aaf6d891764ae0aa8786f8e38a8924",
      "8d2a3a07fabd4354a21bbe826dd37423",
      "f9105028608c4f3ebf2e68f96b762910",
      "c041ec5ccf8f40e6b55c8a9afb438629",
      "587bd08702c440b9a17c7768933cf214",
      "958129a04d7845c99e8b8d764a4e5068",
      "a104fc2a4ff94be6b29979fada5cfd54",
      "31268ae27c4145b0afd72134602a4b68",
      "dae2508c972a40999e5c4654b84c7b9d",
      "a276045bc6ba4e0aa8305b8e523384ab",
      "c3cea7890e3044438d9f0086dd26164a",
      "554452e55c8440e9b76e5f5cdfffae0e",
      "395b4943fab04db395fe64424a9082a5",
      "9a0bfe6f4ace419f8484e7f2f2531b7e",
      "c3e99d362d2f4f0d8ab5154033d0276e",
      "f4a436c04b954c3aaffe0683828f23b9",
      "120ca7cb9a154e95aa16d246c43a4dfc",
      "9c4089d95e7040bbb909442985ac517d",
      "0827c3bca724480eb703aabbcbf0a79b",
      "cc4503cd684242039948f49b188ee69d",
      "ade3fd1f69ab44d1b818d1cdbd6ba96f",
      "568e0f1466ab42f39714a00a94e0de3c",
      "fb4e5af298404049bf8af5cff38fbb6c",
      "f7e12d5ccad34221a71afb03de5c303b",
      "82d2127be09a4a58a1c5b19d9e97010d",
      "075f288ece2a40b5b3e633c2cd7cf4f8",
      "2abff889d256475bbf290db571efb184",
      "084eba17844643c396f7318f046ea171",
      "b0e422937cf94f67b556df2d8249c545",
      "184a11c0cd694bd39917914912d5fccf",
      "2c0499c2908c40b9b0a161c6856d54bd",
      "6402ace48a0846cdad2772d3f8eb0afe",
      "7a1d9229a13b49c5af7a13b77cb1018a",
      "7e471b47b6184d468f49584eee444bce",
      "b4040ff45f724d7a98c626097feca9d3",
      "e227f93ed2d74bcbb39856fb9e6679c4",
      "3350ec4a542844448307b4f44f001641",
      "906f52a151b34fcba2e5eec437db00a7",
      "bd3aeacc67684e0c8b8c143b28ed0a8a",
      "f8c8745686104b81a4215755fa14d06f",
      "1c63f4e8461d4542a3f189b14cf70d0d",
      "e283720960a349edb9580b8e96e63150",
      "52bec46f1e5c42ab90d721294f653f64",
      "8cf08c29ed0949d4ae8b986b3cf05b4d",
      "b3f3228931804cc2857f0616037b207e",
      "a355f0afba464eec9519477fcbbaaa6f",
      "3a75ce90b3924863934696235558dee3",
      "a10bbf38c61b49b5b8c287647d6df92d",
      "610472ea208d4eb3bb357dc2754a81d3",
      "eafc4f2d68044a1289fbabe514ee464b",
      "f6659f4787e146f6a7de8d4276a5ad70",
      "a3230166b5214ea680d720b8f8c15c36",
      "55da63ac20fa490f8995f684409cf940",
      "802e661e41394e989bb42439025d9dd0",
      "651ae77cf5e2483099d3ba5129a87acf",
      "2df0638ca58145d980d8c22cfbdf6891",
      "43ae81fa0fe6410fb74d404bc699f059",
      "28a1747fd25a429cae9dbacada2346cd",
      "1bc91964e0f249ac878655044cfbdc77",
      "db0b7ba606fa4cfdb7731f279cb12878",
      "1b4b766f01e849949902bbb4809b5eec",
      "58855cfbeac049da8470c5f29787d551",
      "56b31d98eada425f8e78784d26f9daab",
      "6237ec59a83f4a97aa2a585e40082e6a",
      "3ddbc569fac448a28fbd264cdaa812d5",
      "af6ff92c637246b88d440406da3ef028",
      "0c47f3a673854776935be8370efe6b26",
      "783d8cfda5f54bec91ef4d22e39ca20c",
      "cfcd35c307ba4c24aabd9b9c5be2b676",
      "4f9bbc4d2a1e4aca820d6c09f2e8ef1b",
      "749ed3bca725455aa2439644bc477451",
      "598f1a8e1c2e4ab6ba75ad8342478365",
      "d101c8016be442c6b4d50cf5e122fc74",
      "73dcb62fa16843e383660a4e0ff456f4",
      "9a6369a5c0134ab3bfbe6f250c8677d9",
      "e6ca9619a4a64c449c2f298040c9bf25",
      "5ec76f1737c54dcabbe50434e4a755ee",
      "82c74a704c134c7a9d91997558679e5c",
      "a128e21f6eb341a0822ae720555b907e",
      "bd23b7e2b5a641539207840fac6e8514",
      "68f147c79f1a46cfada2bef3de579c28",
      "168a7cb8da054de3a03479921206cb02",
      "b36f8871d46346f9b367cd71ac039e6c",
      "0fdccda0c627414cbdf40a451170a4c3",
      "f32dd9a035ca4dc899363ac5c97994f8",
      "e606b5707f8a4971afaa333c0cc51ade",
      "44bd45abd5734040bd66d8097c4ac352",
      "9710e58ce5d0477abc65720377827426",
      "a4b8737d636e439b9810c9b621c029c9",
      "b614df42ca8f4e6e96989e608e47cecb",
      "4b17dddcb5b844a78047ca16cd030510",
      "0eb177695796427d8b71cf157cc51770",
      "70249f5f6b1f4e50988325af0f7a078f",
      "a0d432d70be54517a3b9adbfb23084e3",
      "b18ec99e90be46a9877457cb1ea16816",
      "52259b9b45bd493facd66bef9f3ae546",
      "03ea3b69490b4aa0afe6640e096a8dfa",
      "f7e67d06d5f54c048d80d702d2dd0747",
      "cd39256b2d0f4c2cbe90cc5d1ffd1676",
      "bad1c97b220842f29826f72d8f31b662",
      "8a2e8c7df5c34739b605dfa10940aa34",
      "c3cf71fb440c46b8a9b02cdd3b892dd8",
      "96877af386694b76b4c76780c8cd4024",
      "26b8b4b66ddb42d2b7687e8ba10fede6",
      "798ab793cb5b46a2ad8611a6ba841a58",
      "db9c058e5df547ee9289ea0c83e98116",
      "de200f0223b640f9ba559e9e070b7147",
      "aaf87d07661c4a34b03e2c9f70da02e9",
      "92085546b24c4a6080aa74228e6c3235",
      "b1958402ee5b415d93201a61145e8d3e",
      "3563fbdf534741558b0f22c472ac4fa2",
      "5e0c5ba9bb034978b0161a366e0a0e12",
      "377164007c3a492cb45bb983276c88f9",
      "005daf59e7604075b96f082faf756f30",
      "c91df589def243e8be8a33e3e4d60475",
      "a3dd779dae8946b8aa7252f430f9c2df",
      "3cbcb61e183741f38692d6a30138b58a",
      "4f7bc43c12ad4f10a721836e8f399cdf",
      "ff74aaeaed404ecf9aa2f8e213b34998",
      "08ecd1c0703d4827a4f56039584e1f5d",
      "9de6d6022e5c405fb7f4a30a22ba5373",
      "138be7c5026644978cef975406281383",
      "f79da0588a8e4fc7aa2ee24c70e6112e",
      "9bcdf80c6cab4fcda5f534bd9b65d13e",
      "45555b770471450f849bb5725a403c66",
      "97be59a70edf44f889c4fc7a85742137",
      "7df0d69963844b37b17abe7ce9b8e473",
      "7183a34a492441f7b932ab61b860cfe1",
      "c55940d99ab7473290245d3c594bb020",
      "88d0043425974d1f99e3db455f11ca2d",
      "cc52a28c9cd74f80b358dda0b47718f8",
      "c4cbf9a51693491e8682ed948cf2f577",
      "f86e24d717cf429ca8b444be018d61b8",
      "2873b3083ea04d6d802203267a1ba69f",
      "5d6f8cb6f28b4ddfb554e7026b3bd36b",
      "2c869b098c444b2abc5d9322cd68fa9e",
      "67cef624df3f4ab0b01bea331838cc66",
      "08960719e9324233aae4a3b9c123fb4a",
      "55e874b87a3b4e4cafce70c8a906caae",
      "07c17595a21b4bb68af3526f27fd85f9",
      "ab562da0782a472983db66f48786162e",
      "db5fd0f3b1d24cb58ac139393f99dd17",
      "1469378833d8437f901184b6c6a38551",
      "12a8f74528c644cc898f67a7d18c64d4",
      "b81182af9fcf4a3aa252359cf0109b9c",
      "e793edbe2ec6417ebf2a808a6036c6d6",
      "bb4fe5a446be4e4ba9fb780dc89d8cc0",
      "824064e7d2e8471b9fd22229ddc6a4ff",
      "b71e4555cbcd466d886b1278501aec21",
      "a604889fbe8942ce995b509c0a790da7",
      "7897e425f81547279d2f8f17352b50e6",
      "04de590a348e489488e8003a37043830",
      "a6533658b8c544718e568e860f616c3e",
      "d33e5f4ffd2b49188c98526f1ec4404c",
      "649eee6ec7b3496592637991045f42dd",
      "3ea6a98f180c4a1386761d693265d9ee",
      "e390d6f6d1604c2387f9d84485e7711c",
      "dee5ec4dbdf34fbf9077bc2e89a4f4a6",
      "dc7134b2b97d4991adb641aaaaa12549",
      "4d4f75ae989e4361b129d3549b06e8b4",
      "672efc6864b949c7b77c196c582b6585",
      "d4efb3fa01a14065bb2d355c52adf1be",
      "5919117e52cb49f6b3ac2d5560f84b20",
      "c294957321d44dd196900f42c8c56e44",
      "56908e7d33ff46be927b7ae6d7b3935c",
      "fb961de4111f4149b165b9cf8f4e7be8",
      "4e7a03aefa8a452db03d25e39e0265c7",
      "dc8ae652601948e48b0873cfd5f6c976",
      "c1faeb9e028a4f3da25c707bcfa57c90",
      "915c89f2bc2b41f2a0fa671647de87af",
      "c20eb6af9c1442bea744bf810247624f",
      "50767f99a20f4b60906e3f7ac981015c",
      "c900fdd7be944315b6d084703fd2331b",
      "9287e27b936d40a8a5a862dc7d4c0aed",
      "ff7f2963836744958964c4e5c5a56c67",
      "decaf61ce2ad4430ba0b8b8665036f7b",
      "c54736abbe934595ad1c94802d883ea7",
      "f9cca6f024364459a8d7f6deea4a89da",
      "b0e5e7d206c8403681977b287de79398",
      "666e76a995814bb9b0527ab54c5c95bb",
      "1baaa22b6dbf4dd98662fb8d9a220f4f",
      "4266c5d2567a41e0b9e8d6239cdd3305",
      "ad38ce6332c4451c9ddbd53edc159c25",
      "2fcfd3d7ddf24b6eb9a0560515600ace",
      "0449b77f24144af48810730f7fd84e54",
      "7580c082cdfc4b81b1e83b1727defb2c",
      "467d52c203dc45c681744333bc77f14a",
      "f2915e60c4434eabbd1f04dafd76acd4",
      "cd86a41923b84be5bc625aa3347db698",
      "52d620ebc59d4f96a5431e56463926b9",
      "1786b4f301344da49d27b570279b1aad",
      "0fa406bb1f284e5985166b7f226f4e83",
      "5ee29001125a4c8a8419360a0e87a48f",
      "9229c42b497e4bd885d7364ddd354bcc",
      "c99ca6b834f6451d805610d1c4d680be",
      "e2b4178b20494b6cb4ada65d0a45a1b0",
      "695bf7bd3ea24709b06869b3ac15eb29",
      "bdba5473c1274e44a63f9a28b0b225c7",
      "6494a2013c4a4b38b64e7fd8d96f7abb",
      "2776b6efc6594938bfb658f438149490",
      "afe064e45141480dbbb39116272c1897",
      "9d9ec43d5d27431d89f3c4483440cef4",
      "0f5aa7a8f9ad43fcba3db2548997b4e9",
      "8a1b4c3c1dc64d4c96ce7b742d0316d8",
      "e965bd5f0e214f139f977b13d86cf6ae",
      "1a3931be40d343239a1a48bf573b817f",
      "5803732964104f4c94071fee9c5a1bec",
      "35a34f03d4044dbb9fd3b7bc2c66045c",
      "ef731dfd0e0c4d86940d4de8faeedb41",
      "603e2e35bdee427bad7fcfc39fff2ea4",
      "dac683a4cbad4cec94a95cbcacfc2b86",
      "3bc1855ee11041568e7d88f69a29d4b3",
      "cd61c31aa3114d1bbd173ac8a595b31b",
      "64681b8a505d40ce8b69fdaa0640380e",
      "8afaa6b348304179988a7bc948665a23",
      "4f6f4a1440af4757bfa1ac4208e45e7c",
      "0abd05770b2d4cbcb096830538c2d7da",
      "7bfda9f0246f4ef588b833cd15120043",
      "c836f1b1151146f8a762928c4c083c8d",
      "0ba03487c7264cb2b8c645cbc04328e2",
      "dac5f4322f934946a14846b04c373d18",
      "7cb9f6e248084fbb8a61580532e2f44c",
      "e00f277e85084e0cb9dedef8b89975b8",
      "22fec13914894a56be2c0482b518c337",
      "459dbff1f6c843fa8659a691954561c9",
      "4fee4cd554ef4153bb37748bbfce24fa",
      "267f3469160e4461898d4910da901782",
      "e4d2fc11b5ee4b289a902ee6239e0571",
      "7c938a8d6bea44469f47a43eb4e4195e",
      "83882443db7a44aeb1e7f01bdfd13ee8",
      "6067f95e47764b708ac1da0f1f823371",
      "d18c149828034fe1ad6fcfc2951be570",
      "cd00f3c2a9e544c59408a6e043d004c0",
      "a94544de7aee4256b4fa914baadbcb19",
      "9db59999405243d6bb6d4f6975320a95",
      "66e16ed2deb04063a86ad541d95c11f0",
      "0a410d92ed0646099b55b7779c716757",
      "d2945c2b48e64cb8b1d92b6306d6439a",
      "bfae55fda181499fb95f5d362902027a",
      "26be1c256a0d49afbefc8a1e26d57123",
      "2dae46a511f841d6a9b6e1940246565a",
      "c0a0ca820a92414295bd650cdbc14c69"
     ]
    },
    "id": "jPFaZa0Am-aN",
    "outputId": "72266872-fcb5-4f27-8764-98e4e2d82d85"
   },
   "outputs": [],
   "source": [
    "!pip install early-stopping-pytorch\n",
    "from early_stopping_pytorch import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(patience=7, verbose=True)\n",
    "\n",
    "EPOCHS = 20 # You may need to run longer to get better results. Lab example is for demo only\n",
    "\n",
    "# keeping-track-of-losses\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in trange(EPOCHS, desc=\"Epochs\"):\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "\n",
    "    train_loss, train_acc = train(model, train_iter, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iter, criterion, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best-model.pt')\n",
    "\n",
    "    early_stopping(valid_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSaOuT-gv0wc"
   },
   "source": [
    "Example code to plot losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7su0E10QsoLG",
    "outputId": "6b54e41c-80bc-47d6-ac9f-809c09bd0e3d"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLg-UGiOztuD"
   },
   "source": [
    "Loading the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rm0fXD2ltfoH",
    "outputId": "45a8a775-1efd-4e08-9eca-e544f2d6a29a"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best-model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pq_2cz0xgwtm"
   },
   "outputs": [],
   "source": [
    "images, labels, probs = get_predictions(model, test_iter, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W1S4ee_3g_Oy"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('/content/drive/My Drive/Deep Learning/ISIC_balanced_split/ISIC2017_Test_GroundTruth.csv')\n",
    "y_test = np.array(test.drop(['id'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 925
    },
    "id": "H6utF06dhZ6o",
    "outputId": "7f80f37f-7c10-4d95-e93c-5251c9131f09"
   },
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "import numpy as np\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "#change to OneVsOneClassifier for generalized AUC\n",
    "#from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "#from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "n_classes=2\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], probs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), probs.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[1], tpr[1], color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[0], tpr[0], color='green', lw=lw,\n",
    "         label='ROC curve of Melanoma (area = {1:0.2f})'\n",
    "         ''.format(0, roc_auc[0]))\n",
    "\n",
    "plt.plot(fpr[1], tpr[1], color='darkorange', lw=lw,\n",
    "         label='ROC curve of Other (area = {1:0.2f})'\n",
    "         ''.format(1, roc_auc[1]))\n",
    "\n",
    "# if you need more classes\n",
    "# plt.plot(fpr[2], tpr[2], color='red', lw=lw,\n",
    "#          label='ROC curve of third class (area = {1:0.2f})'\n",
    "#          ''.format(1, roc_auc[2]))\n",
    "\n",
    "# plt.plot(fpr[3], tpr[3], color='cornflowerblue', lw=lw,\n",
    "#          label='ROC curve of fourth class (area = {1:0.2f})'\n",
    "#          ''.format(1, roc_auc[3]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curves of Proposed Method')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Ly7GDpRritFY",
    "outputId": "a5fcfe0a-f5fb-467e-9b1f-24fa59b34f32"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from matplotlib.colors import Normalize\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "pred_class = np.argmax(probs,axis=1)\n",
    "true_class = np.argmax(y_test, axis=1)\n",
    "\n",
    "cm=confusion_matrix(true_class, pred_class)\n",
    "class_names = unique_labels(true_class, pred_class)\n",
    "print(cm)\n",
    "print(class_names)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "C = cm\n",
    "divisor = np.zeros((2,2))\n",
    "divisor[0][:] = 117\n",
    "divisor[1][:] = 483\n",
    "cm_normalised=np.divide(cm, divisor)\n",
    "print(np.transpose(C.sum(axis=1)))\n",
    "print(divisor)\n",
    "cm_normalised = np.round(cm_normalised, 2)\n",
    "disp = ConfusionMatrixDisplay(cm_normalised, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FMdlbRvPNR9Z",
    "outputId": "dcb73652-75d1-48ca-da24-e0221bb65835"
   },
   "outputs": [],
   "source": [
    "TP = np.diag(cm)\n",
    "FP = cm.sum(axis=0) - TP\n",
    "FN = cm.sum(axis=1) - TP\n",
    "\n",
    "precision_per_class = TP / (TP + FP)\n",
    "recall_per_class = TP / (TP + FN)\n",
    "f1_per_class = 2 * (precision_per_class * recall_per_class) / (precision_per_class + recall_per_class)\n",
    "\n",
    "weights = cm.sum(axis=1) / cm.sum()\n",
    "precision_weighted = np.sum(precision_per_class * weights)\n",
    "recall_weighted = np.sum(recall_per_class * weights)\n",
    "f1_weighted = np.sum(f1_per_class * weights)\n",
    "\n",
    "\n",
    "print(f\"Precision (Weighted): {precision_weighted:.2f}\")\n",
    "print(f\"Recall (Weighted): {recall_weighted:.2f}\")\n",
    "print(f\"F1-score (Weighted): {f1_weighted:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
