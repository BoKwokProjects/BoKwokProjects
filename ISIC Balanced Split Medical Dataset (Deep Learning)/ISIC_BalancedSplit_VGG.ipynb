{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "39882194"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn import decomposition\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "from collections import namedtuple\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import collections\n",
    "import math\n",
    "import pandas as pd\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6061aGw4pM0w"
   },
   "source": [
    "If you want the result to be reproducible, you will need to set the seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QrPC2sxvRkvX"
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zSV0OKw4pY14"
   },
   "source": [
    "Mount to Google drive and unpack your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-h6147Klo6y",
    "outputId": "41a38e8a-4f5f-42b7-aeed-b1f0fd0ac26f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4B7PKK1Y1FYV"
   },
   "outputs": [],
   "source": [
    "#import shutil\n",
    "shutil.unpack_archive(\"/content/drive/MyDrive/Deep Learning/ISIC_balanced_split.zip\", \"/content/drive/MyDrive/Deep Learning/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_VnoD_lpljb"
   },
   "source": [
    "Run calculation on mean and standard deviation of my train dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvEG0dSopraz"
   },
   "source": [
    "This is an additional code to check the mean and standard deviation of your dataset - you can then use it to replace the values in transforms.Normalize to improve your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xVKKboX9znM6",
    "outputId": "6c7d6776-50a4-4ddf-f31e-015f515b5919"
   },
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(root = '/content/drive/MyDrive/Deep Learning/ISIC_balanced_split/train/',\n",
    "                                  transform = transforms.ToTensor())\n",
    "\n",
    "means = torch.zeros(3)\n",
    "stds = torch.zeros(3)\n",
    "\n",
    "for img, label in train_data:\n",
    "    means += torch.mean(img, dim = (1,2))\n",
    "    stds += torch.std(img, dim = (1,2))\n",
    "\n",
    "means /= len(train_data)\n",
    "stds /= len(train_data)\n",
    "\n",
    "print(f'Calculated means: {means}')\n",
    "print(f'Calculated stds: {stds}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYSwCw3Rpsx6"
   },
   "source": [
    "Image resizing and image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3c34f65"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "transform_train = transforms.Compose([\n",
    "    # Randomly crop the image to obtain an image with an area of 0.08 to 1 of\n",
    "    # the original area and height-to-width ratio between 3/4 and 4/3. Then,\n",
    "    # scale the image to create a new 224 x 224 image\n",
    "    transforms.Resize((32,32)),\n",
    "    #torchvision.transforms.RandomResizedCrop(32, scale=(0.08, 1.0),\n",
    "    #                                         ratio=(3.0/4.0, 4.0/3.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    # Randomly change the brightness, contrast, and saturation\n",
    "    transforms.ColorJitter(brightness=0.4,\n",
    "                                       contrast=0.4,\n",
    "                                       saturation=0.4),\n",
    "    # Add random noise\n",
    "    transforms.ToTensor(),\n",
    "    # Standardize each channel of the image\n",
    "    transforms.Normalize([0.6938, 0.5495, 0.5302],[0.1293, 0.1447, 0.1579])\n",
    "   ])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((32,32)),\n",
    "    # Crop a 224 x 224 square area from the center of the image\n",
    "    #torchvision.transforms.CenterCrop(32),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.6938, 0.5495, 0.5302],[0.1293, 0.1447, 0.1579])\n",
    "   ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QeeGwNRet7I6"
   },
   "source": [
    "Reading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e18iATu92qHz"
   },
   "outputs": [],
   "source": [
    "data_dir = '/content/drive/MyDrive/Deep Learning/ISIC_balanced_split/'\n",
    "\n",
    "train_ds, train_valid_ds = [datasets.ImageFolder(\n",
    "    os.path.join(data_dir, folder),\n",
    "    transform=transform_train) for folder in ['train', 'valid']]\n",
    "\n",
    "valid_ds, test_ds = [datasets.ImageFolder(\n",
    "    os.path.join(data_dir, folder),\n",
    "    transform=transform_test) for folder in ['valid', 'ISIC2017_test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3FOo5_B22uae"
   },
   "outputs": [],
   "source": [
    "train_iter, train_valid_iter = [torch.utils.data.DataLoader(\n",
    "    dataset, batch_size, shuffle=True, drop_last=True)\n",
    "    for dataset in (train_ds, train_valid_ds)]\n",
    "\n",
    "valid_iter = torch.utils.data.DataLoader(valid_ds, batch_size, shuffle=False,\n",
    "                                         drop_last=True)\n",
    "\n",
    "test_iter = torch.utils.data.DataLoader(test_ds, batch_size, shuffle=False,\n",
    "                                        drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TN7aGI-S3JHm"
   },
   "source": [
    "Show image - display some of your images for observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7UW0sqDsRxI1"
   },
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    image_min = image.min()\n",
    "    image_max = image.max()\n",
    "    image.clamp_(min = image_min, max = image_max)\n",
    "    image.add_(-image_min).div_(image_max - image_min + 1e-5)\n",
    "    return image\n",
    "\n",
    "def plot_images(images, labels, classes, normalize = True):\n",
    "\n",
    "    n_images = len(images)\n",
    "\n",
    "    rows = int(np.sqrt(n_images))\n",
    "    cols = int(np.sqrt(n_images))\n",
    "\n",
    "    fig = plt.figure(figsize = (15, 15))\n",
    "\n",
    "    for i in range(rows*cols):\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "\n",
    "        image = images[i]\n",
    "\n",
    "        if normalize:\n",
    "            image = normalize_image(image)\n",
    "\n",
    "        ax.imshow(image.permute(1, 2, 0).cpu().numpy())\n",
    "        label = classes[labels[i]]\n",
    "        ax.set_title(label)\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rucCMNrqNsX9",
    "outputId": "ac63486f-e0e9-4f6c-95cf-baab46e8b582"
   },
   "outputs": [],
   "source": [
    "N_IMAGES = 10\n",
    "j=int(len(train_ds)/2) - int(N_IMAGES/2)\n",
    "\n",
    "images, labels = zip(*[(image, label) for image, label in\n",
    "                           [train_ds[i+j] for i in range(N_IMAGES)]])\n",
    "\n",
    "classes = train_ds.classes\n",
    "\n",
    "plot_images(images, labels, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NETRAKM8qW4v"
   },
   "source": [
    "Define the CNN - this example will focus on VGG\n",
    " and its variation. DO NOT CHANGE THE CODE IN THESE PARTS. MIT License: Copyright (c) 2018 Ben Trevett."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wxq-Q9K9kzBw"
   },
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, features, output_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = features\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(7)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.classifier(h)\n",
    "        return x, h\n",
    "\n",
    "vgg11_config = [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
    "\n",
    "vgg13_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512,\n",
    "                512, 'M']\n",
    "\n",
    "vgg16_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512,\n",
    "                'M', 512, 512, 512, 'M']\n",
    "\n",
    "vgg19_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512,\n",
    "                512, 512, 'M', 512, 512, 512, 512, 'M']\n",
    "\n",
    "def get_vgg_layers(config, batch_norm):\n",
    "\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "\n",
    "    for c in config:\n",
    "        assert c == 'M' or isinstance(c, int)\n",
    "        if c == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, c, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(c), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = c\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTbbA3M4q6Y0"
   },
   "source": [
    "HERE you can start to define your model, you can use different vgg for your work. Change the OUTPUT_DIM to the number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DiOgETzglDMN",
    "outputId": "b0e4f85d-2642-48d8-9135-e2037ef3c737"
   },
   "outputs": [],
   "source": [
    "vgg11_layers = get_vgg_layers(vgg11_config, batch_norm=True)\n",
    "#print(vgg11_layers)\n",
    "\n",
    "OUTPUT_DIM = 2\n",
    "\n",
    "model = VGG(vgg11_layers, OUTPUT_DIM)\n",
    "#print(model)\n",
    "pretrained_model = models.vgg11_bn(pretrained=True)\n",
    "#print(pretrained_model)\n",
    "IN_FEATURES = pretrained_model.classifier[-1].in_features\n",
    "\n",
    "final_fc = nn.Linear(IN_FEATURES, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wrROb1bETFDy",
    "outputId": "7e04f624-a21f-46c0-8b4c-0af1259df054"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w5yE7GYedACj"
   },
   "source": [
    "Setting the hyperparameters and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ha6oXvmRdDUL"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "FOUND_LR = 5e-4\n",
    "\n",
    "params = [\n",
    "          {'params': model.features.parameters(), 'lr': FOUND_LR / 10},\n",
    "          {'params': model.classifier.parameters()}\n",
    "         ]\n",
    "\n",
    "optimizer = optim.Adam(params, lr=FOUND_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sCPodX8Md-58"
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim=True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bpvs2GyNmtT4"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for (x, y) in tqdm(iterator, desc=\"Training\", leave=False):\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred, _ = model(x)\n",
    "\n",
    "        loss = criterion(y_pred, y)\n",
    "\n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion, device):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in tqdm(iterator, desc=\"Evaluating\", leave=False):\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            loss = criterion(y_pred, y)\n",
    "\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t-PrMgRvekuh"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Q-CwCsRgu8N"
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, iterator):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in tqdm(iterator):\n",
    "\n",
    "            x = x.to(device)\n",
    "\n",
    "            y_pred, _ = model(x)\n",
    "\n",
    "            y_prob = F.softmax(y_pred, dim=-1)\n",
    "\n",
    "            images.append(x.cpu())\n",
    "            labels.append(y.cpu())\n",
    "            probs.append(y_prob.cpu())\n",
    "\n",
    "    images = torch.cat(images, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    probs = torch.cat(probs, dim=0)\n",
    "\n",
    "    return images, labels, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "a89a885bbdf84cf788c5ab8f0a88bb15",
      "8081d08c7a5e4b27a9e0b169326f69ee",
      "deefa474c35b4c17a945bfc0be0f9287",
      "7dc153971b284178a170dba2aa52b6cc",
      "9d3044ec6cc24fa6b7e1fe0c0be901c9",
      "68a22d321d4e43cc9b9df921e13b6e6e",
      "acfbe36223b048a9b895bc3045f8c07d",
      "a78e215e0fbe45b6be7f07be67fe9df2",
      "f0a4ad2202534320b6fd94d1157ada16",
      "6c4a0e25b41e40fea57b715eeb73d00b",
      "f696cf50f92042878bbeec8a1737db1b",
      "2ce2ccca302249f88bc099d10004ad22",
      "eb25c20485ea42e1a7bfdf9f3481dd9f",
      "b41a022fbbd149cbaeb54ad260d236c9",
      "4cac429d119b4388be7168c9214cfd23",
      "ca680fa2ae124e8aaa29f4747a3c5cb1",
      "0c9c5e3fae5e436ab199ff5c507f7260",
      "1220e02c926d47859904e5e403d3549e",
      "2ece47ad1b6d45628b91efc1e1c1ad7c",
      "6601bccfa089441fb8065b424fcba95d",
      "7e70b93b21e447bdb9511a29c7a2d2fb",
      "f205dd37b4ab49d6a8675188d4d97ba2",
      "6ff9d3950e3d4b458089c27f510e0afa",
      "b1620f84f8d246d681899b192cd8774f",
      "21ade01b314248cfb1d4d0c48b67e931",
      "0b13bc26768b4594b591f46852670826",
      "ac97a6939aad4139951cedded219a2c9",
      "d48b2141e0514586991b2ee313b0a9bb",
      "7ba63b0e639e4d38950dec20563ea470",
      "018b68ef250d4f98a180cff125c5cfa6",
      "93e5d454d3a749eba04e5b862577a222",
      "47211fc0c25b4e04bb9bd1429b757a97",
      "aa64bf818dfb461ebbd2bfd10f28a77e",
      "e6e479c3602e4a8a89144336028cbfad",
      "f2bbe8e4ed4c486fa45746ae87b158b9",
      "d98e76b759b64348b381436e04089f11",
      "cbbf70fc9d51447db537ae0595e5b0a9",
      "8ea4d99786534d6e859c216c056aa1f9",
      "945024de39024235a5015e7411519bf8",
      "829ee25a923f4466bbd18c417aa4b7a1",
      "e63341f5cdb940b494df73eb42d804b5",
      "63d62dbec6524abaa9375dc3584797dd",
      "3c854409664c496aafde19ea8668e41f",
      "13e82804b7b741df9efada458ade0686",
      "9b4e926c70024a3cb453698fba14b0c4",
      "11ac0863ab4947ac9176a5d2fb63b971",
      "d44c0a5ad58548bba7147a05350e9eae",
      "2415765a0af344d0a5b6a3d00fa8ab13",
      "10fc959ab9a34b1d886ebc272b8f124b",
      "6c76e1a876514b629aba4c1b4d9570db",
      "8a42648591bb4464b6c50f491c278f7e",
      "b1379f6b20d446a99679a7f2239d8c61",
      "b94db9dac2e546d595ac8a0f27b16821",
      "48b88706d2934a58aec8a08f57b7bc51",
      "a34050f71a0e4146abcd48434f783cd6",
      "151d4a69d9f3446aa4a03835c93ac7f4",
      "439dc2507a494f6cbef7a8d35ea679dd",
      "612df5b131924a1eb048fd7a211fd27c",
      "5012c29f297840c89c86366bd39be62b",
      "d2ab09fc4b9942eda5ed900af90daedc",
      "2d97f8e74c85454eaf91217754aeb149",
      "d0de4f135da44a439a1a48a66225d6e2",
      "c82de725637b4ee59c5612e8ade85694",
      "35637f3645164c8baa272f647ca53d72",
      "8d7dc225c8b5416887175bc12ce7d298",
      "100107ad33e94a9ca7f57c98ce69309b",
      "587fe09205cb4b1aa99b8396010e8da2",
      "e729653717f24acd969fe31742214751",
      "51fa429a43fc4bd792ecd2a80e9ecbb8",
      "a72b4f040d954af9a1cdedeeb52a9eb1",
      "bb73c829c6a341419eb82c5bbd95c5c0",
      "954720029a5e46f99f0b9273eb75e663",
      "fad09f23f20a435caff57774a326d18c",
      "d83abc4839fe48d888348ac94d0a0779",
      "e622e140c5a845b7b787ba10075ddaea",
      "5982e4b36ad34b43a7c61b2e43730632",
      "ddd791914a1744dbb4670c921f821ed6",
      "43db245751b644028803f7d53d352a9c",
      "4d63c7ad5b3045b6bfc77bc89bb1f999",
      "13813179c1774478a0b44bb713dcce75",
      "76c9335c5c7d4b848b58acd9978a9502",
      "8495f7a3e34c4280b30e28d275b296a8",
      "3fc33c4743924e4c8b248b79a71899dc",
      "1ff873571c99429d9f51f6d50c006d6f",
      "47bf51dbd3ea46d5919be00ead1eade2",
      "d9562fc15d9e4563ac7b3a2765edac45",
      "9ff2a8cc1a4544c983c8a88c57568e24",
      "1e6568f7e876477d986ae37f95d4c571",
      "1ec9f0a0787446e392d2f50ab8e7532f",
      "444fb49e8cbf4596bc401ecbf6516ccb",
      "b49cdfe39e5f418ea5bd538d7df5169b",
      "9550cd7177c647048bc9e2a3dd3468db",
      "666ae50f33c04918a2c80bbb983d7fcb",
      "22ba6c8381fd4f19a63eb528a7998bee",
      "e4a2d1a577294a2eb8fd4bd49b7e4b2d",
      "c6e65ec46f5848319312cf19f9c5f957",
      "93701401193f45c8b5243b448be24623",
      "02acbee52f1646218eee88ab8e467b99",
      "3daa34877e5b45edb37e27a3239e92ca",
      "931b4d2ac0e64796bc0c4559dfe14cf0",
      "9e30bcc61f264166aaec6a263e368447",
      "0dc541d9053945ba8d0beafe9a96ba26",
      "04a897e2a19d4de0a64bb0be700d3b55",
      "ffe864eb0ec245a89bc0e07a12d87b9b",
      "baa93f5c838d4e58ae65c689de7751d5",
      "71ec1a759362429e8233333f8b0b11a6",
      "5c2b70d6bdc34590ab8332510dd00312",
      "7b3a3d2db70043c4b4b84510139ec851",
      "59d1f6e30d6c4c21a940e5f8019c6f6f",
      "d450aab9be484b9eb8d903e86a0e46e2",
      "b2877ca7697346f3b007df9857c55472",
      "ee19b9555ccc40c18a09d66ece3788bb",
      "344d3bee3ce942909c67e8c443854867",
      "7a997b93ca2c4be49c475d23e8d4fb22",
      "5d3d3c652b2c459ab502923cd03598cb",
      "3bd2237283b04de990be1e49414228f0",
      "061fdcf8bd0645a7b0214c71e39c2d42",
      "75b596f5eebd43a2a5b4838331c71691",
      "0cbbe10577ef4ba39d18abe68a63156d",
      "a12f3c3bae9245b0aa2dccaf8ac74367",
      "2b169a3daa284455bbe742af62bfa6bd",
      "028d796a0e6d42cc944c34af6b7ee524",
      "b5a25b8d449d456db4e8124b2c3dd237",
      "c6c8982d3abd41d9b2b7712cee09d1a6",
      "4284798ebec64d9ea656c2be6bcda62e",
      "a5dc14bf26f04691800592470ad7d5ac",
      "48c488e5015240c687748c42692b3162",
      "dbf8f0bae97a4871a852bc8c2c60b8a3",
      "e252b476818541d5b9082ced3b913315",
      "49e1bd1770294e029c7082b4d96cfa3c",
      "07d29f2475ae4c9f93043a6f9b3fe6fe",
      "a6e6e94362e941ef8279bee6c265d4be",
      "b895945f76ef4410a69f1eb5a3fea742",
      "c72ba3dcb8d0468d904aa6af80b57e07",
      "a8f528ee0d0140029d42dcc877c8fc65",
      "6bdbebaff487474493846bc9b254855a",
      "dcc2644c17644b77be697b959a1de2d6",
      "c14d929910e5449983bf9c38f7b70623",
      "3708fc1e3eff43348318f41cd3c36dac",
      "c1d53471089b4a589a478d3a13f25561",
      "4a977663f6d04bfe8572bda25a5ca4c3",
      "eb501675b00a493cad648b958247214e",
      "f25049d3eeda479dba253dce00c34ad7",
      "8b44e2249c0049b282224172fcf6f85b",
      "25f91e37641247e18e09d26a4f752dd8",
      "7056d1921df84531b2a66b04988e396c",
      "bd18539ff583427180b829d99b31ed02",
      "86f7b2c5da894056abdbd3664c5940f4",
      "7e5cd8a137cc4d3cb7e8a62a8ea6a58f",
      "1d4b3ea7d3d8432e8d673d1c08efaed6",
      "23ec01ae644e4b62953f19aec3ce2500",
      "6e1faf6d40a4476e9bdb1aa500e14f8a",
      "38562851de8d44c69d3331f02864ba23",
      "62a456c7122e4f678c499677f5fd46eb",
      "4ddb769d8a684665b77a50f2555e80a5",
      "857f3dc814b14fe2b6c1027c3f2774df",
      "77e7624ebb92474b9929a5a97ad1f5ae",
      "2e2417a1a8e545029de65d1f1f93b4bb",
      "daf69f59c66649f9b8b7e4a463025e57",
      "e9b17d7a525d4b24b31a31c4528541b7",
      "f01ded3d1b2d47dcb25ebfd34e977c31",
      "8d75415cb6014c3c865eb84a43739fd8",
      "52ac9371b5ca40608c1a56182ed557c3",
      "f40676c82fbc48b887981dc4304a39b6",
      "37eb2b266cf2472daacf57d087143d8e",
      "e017e5aae36941bb92c95e692a01701f",
      "cdc46142a239433e81a9222d796b8413",
      "9023d015384e4f418c1713203013c857",
      "f1d77a2f4fa34cc183b1a32fce2b7dba",
      "01c1114cf1c84dd5baf5733f665db84c",
      "163a720803744abbbe5edf9fe7f0a998",
      "d9f713c14a3347499687adaeea4f2e07",
      "a19423faa891477a9a79986d0153c2d3",
      "7b2f57c0fd884ab0958b3645aab83f28",
      "8ed36a3d52b64aa481351adb7b8bd67e",
      "e052edf58da44a789808570d322ba4c9",
      "58e15f69c9d54be284b908363a59347d",
      "565a027ed3a947ebae36428b0cb7d78d",
      "06989dcfa8bc40dfbc59d55b1eb30ab8",
      "ee2891ca6fb4472c8fd947185b3b7e1c",
      "8c6f5c9a8f04457bb23fa10a47350c50",
      "06ce12f0a45b496984f50a42061f3b85",
      "69631845c639433294a0b136ba0a91be",
      "8612f6bf4a4f460ebc83be931303b279",
      "41e34943a54046ab9d5179a16d742514",
      "b2b57b0e42ff408aaed3e905df72f78c",
      "27bb88ba6e4a49b78a2455cac5970c2c",
      "31db520688a041f0b14131fed828b3b4",
      "c3447e1b46714ac9b58d91f33a8a24d6",
      "627d21b62d564d9384645fea197e8031",
      "514bc99856b345cdb8c8f693a82c11d7",
      "733cc2d7941843d6b12b56f0e912971c",
      "a0ef64403e224c0faada48f1b21063ba",
      "5eaca7c4c4924db4a43d3c3acb3714a3",
      "5633760a376a476d9270907f80fa4d92",
      "049b12e808884e0a9b3e8649e6437c54",
      "12ea00537561484984561802221e901f",
      "1185ffa9cea743ab89016435d5b3648f",
      "e0b3ebb404ab41909f4171c4b667fe82",
      "477e7557d08e4694bd24e0ff97b9fb0d",
      "3d020e642880436b981885fe27b8dfd7",
      "dd992d3e33184089ad7c1fa17b11d2e7",
      "3c0d42cd62bb48828a4893d46fa3d23f",
      "8807278e1e5e4cabbf13d5dbb1e84e93",
      "47cfd6df8d6b425cb79a68d993ee8852",
      "93ad9ff989174d378bc7e3511c742301",
      "c3896d3850c64eac85b6a5da19499a28",
      "1baddc1f5d28414d8d1d778650aac8e7",
      "d7c9e898d7e34bb4a7d94e613b0ed273",
      "9bb89d3766a843baa278e3d138fe8a9d",
      "53a9334c35e146d08827a623e8b0d6b0",
      "371d861259574fb1a5f8b9f971644452",
      "e185b5b8dc9b4573b3e9c118e25dade2",
      "3a2f79266b4749cea3a7323139160ca6",
      "9a7f1cac743249508d1a7cb5b7584c1e",
      "f4db097b88c34ac1974e67d9f43a8a79",
      "4f5d015d07f443d68c5e2d623368de0a",
      "066370e0014b43f98b8b9bbaa1c64eee",
      "6cbdf3d190324495be39e519e39d826c",
      "0b128e1b1f3c491d8d6b59620860288d",
      "9d18ba2bfd264fbf9d927760d916e10c",
      "d39c12dda47848efb1f7763339cf174e",
      "aecc7d8b114144f4837b766d6c80b6e9",
      "1e25d81cb7bd40a892539c1b97ab3f55",
      "40935cb66ffe4da8841ac752d58f5c4b",
      "93c22825141447cd9ed70f6cc7c2068f",
      "cb17f4089e97456ebab8db29742efff0",
      "ce35a1967f4146178d4b63abce2961fb",
      "5114b83d2e0f47159bad1464bed26eef",
      "55678071c546498294b0fedc91b24d13",
      "af8cbce8afbb429393aee79f5d9f9023",
      "97b48cc16b6148a29ffae1924964db9f",
      "79c0bd4f4b7748c7bbd500f03813d4d4",
      "b04ad1e6f42240babbb41b2e028ef5fb",
      "19a2126b0000423aa4e92c1a23e1371c",
      "0897fd606782437eb1eba1a3d67b9f09",
      "dfc4861fb7864951b0c2641b41d57579",
      "ccd02babeed0428296c6756fca2cc20a",
      "6d846430c783485cbc03890a123ea629",
      "7d9907c565334120be07cf160b719a5c",
      "0b8f967f7d4141fe894a1556edb22d79",
      "3b4ca325a53d49a692f1c87adfde179d",
      "fcd92f80d5a34ebcb52fac611e6fc9b1",
      "e0c5e20efeff4391a3e524143c428917",
      "a82bdc118a134963acb2854f1cdfddb7",
      "029dadce3d9d4c1abcec1adda9042570",
      "a7134e22e9374da3857463340bf3fa1d",
      "1e529bca2d1d4169984129b8b685af00",
      "94dac5b861af4116a8c71e4bf54561cc",
      "5a696334ac3b47adba42df685d2e043d",
      "e9fcd61a5a5d4013a115b90478a50423",
      "73d22e1bc61d464bba50bb33500439f5",
      "902982b2d67144bd926f0785e601d38b",
      "cf44ae80a61f419289cf312c092ca680",
      "430faedd3cd045f39950c3f772983d2b",
      "3ad021d3d042433985e071833c4405a6",
      "c1245c5090c146b48da0e014d7de4842",
      "fde4573fdcac4718965f398bdb86d739",
      "0f5636bf32114891991107ab8d7bfc9a",
      "c8908321077b47549837a3739113a772",
      "e659286560bb4c4f844f7f5e1e08e231",
      "cdc5ac88a49943908cbd1016bba72e2c",
      "a6a6816ed1ef4f43a8c1d646fbf369aa",
      "1a15831401dd471e9bc1a7eaf90b4717",
      "cd04a1da01374b25aff27d0510d05985",
      "6a987ff3e07e470e82d2f84b8c24c1ba",
      "2d06bef108a14b3a9aac284f4317bfa2",
      "536aaff3ab764e4dac29db97044da4f4",
      "f793c5586c0b41ee91df9052588687d2",
      "16d06034f102484d872ec26dfb9e5d23",
      "e281ee0f5c9647dda6600d78f84c9062",
      "3abd26aa6cfb44e5acaf21e28a1a6f30",
      "cf0391f8d92e4a0c9b95618c392a0015",
      "5e8201697c134c4eb1ab74ebeccdd0dd",
      "a6e13a521dfb407c8e12c94d12756023",
      "567c82801d9a4c9988364159998133de",
      "e488ae1e46904f268b8488bb89754342",
      "8c385f8b25e245638e4364f6f3fec953",
      "5edf98b3cb7e4713a6822f26313cbe25",
      "4216c7541973448dab54fb374b018f66",
      "438addc9a6904b148be1087347208996",
      "2bf44465ece24165b04bfe87f16f87ef",
      "69f81d2b7447476ba3f2163bd0c25355",
      "dd9b2dc3ff5240e6ba5f25001cfedea9",
      "c8cc8f698608452aa3b97637e3b8e69b",
      "9ce9eddeb6344035b53526e4718d6c0d",
      "0be90e1c1a41426487ac6e381e5a3426",
      "3466be4941764b22873270427bba5e2a",
      "8a1fe1bdf92e4c1b9ff7a63da91d31b9",
      "a1b5ae43d6f84f8a92f2782f12e4a44e",
      "8e3970d81296473e989681f036ea7dee",
      "bcc61a96b4f040f8b9b28dde48ba8b5b",
      "94fc05a77de44edeaf2b115ecc2188a7",
      "2c005c1fed174a8ea84e6de3bab1e9df",
      "1d88fa0e063d4c4a854a06b7f7651afe",
      "24792fe51a714331b216c374d222008f",
      "9bbeadeaff9a42a09d9cfeb659280d28"
     ]
    },
    "id": "jPFaZa0Am-aN",
    "outputId": "a9f5e54b-93e0-4559-a029-6a0b412d54eb"
   },
   "outputs": [],
   "source": [
    "!pip install early-stopping-pytorch\n",
    "from early_stopping_pytorch import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(patience=7, verbose=True)\n",
    "\n",
    "EPOCHS = 20\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in trange(EPOCHS, desc=\"Epochs\"):\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "\n",
    "    train_loss, train_acc = train(model, train_iter, optimizer, criterion, device)\n",
    "    valid_loss, valid_acc = evaluate(model, valid_iter, criterion, device)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best-model.pt')\n",
    "\n",
    "    early_stopping(valid_loss, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLg-UGiOztuD"
   },
   "source": [
    "TODO: You can load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PYQXoPMBn4Bt",
    "outputId": "5d298329-d4a8-4d33-9036-47d15ad833eb"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best-model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "727108195fed499183e003065d3379c5",
      "121b434c2d564c38a197a7758db9e9ca",
      "015c851c6bb24e2ab30822186b93e659",
      "4a758259a30542d99d7f5dd77f11a9c2",
      "b73a3d90f8ec42199774943a57912e9a",
      "38603b12ac474d4dabe6af1ade3b00f2",
      "5ce85f427c174767a0cfba8580679180",
      "0da5ec204f5c40c3a5a6a6e0cb917801",
      "ccabdb8feab142e3b179dad8a2bf456f",
      "da4de990f141457bac641b3c447e55c3",
      "9985f206f04d475e968d0a7e6ede5662"
     ]
    },
    "id": "pq_2cz0xgwtm",
    "outputId": "96e037a7-e425-4d0b-ecc8-f6a59f759aa0"
   },
   "outputs": [],
   "source": [
    "images, labels, probs = get_predictions(model, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kjbHuEwaAuOE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W1S4ee_3g_Oy"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('/content/drive/My Drive/Deep Learning/ISIC_balanced_split/ISIC2017_Test_GroundTruth.csv')\n",
    "y_test = np.array(test.drop(['id'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "H6utF06dhZ6o",
    "outputId": "fec51247-c9c1-40da-d89d-6d9abd4bd28d"
   },
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "import numpy as np\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "#change to OneVsOneClassifier for generalized AUC\n",
    "#from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "#from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "n_classes=2\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], probs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), probs.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr[1], tpr[1], color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[1])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[0], tpr[0], color='green', lw=lw,\n",
    "         label='ROC curve of Melanoma (area = {1:0.2f})'\n",
    "         ''.format(0, roc_auc[0]))\n",
    "\n",
    "plt.plot(fpr[1], tpr[1], color='darkorange', lw=lw,\n",
    "         label='ROC curve of Other (area = {1:0.2f})'\n",
    "         ''.format(1, roc_auc[1]))\n",
    "\n",
    "# if you need more classes\n",
    "# plt.plot(fpr[2], tpr[2], color='red', lw=lw,\n",
    "#          label='ROC curve of third class (area = {1:0.2f})'\n",
    "#          ''.format(1, roc_auc[2]))\n",
    "\n",
    "# plt.plot(fpr[3], tpr[3], color='cornflowerblue', lw=lw,\n",
    "#          label='ROC curve of fourth class (area = {1:0.2f})'\n",
    "#          ''.format(1, roc_auc[3]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curves of Proposed Method')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Ly7GDpRritFY",
    "outputId": "64ec29ce-9e03-43cb-a5f8-eebf14b6d24b"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from matplotlib.colors import Normalize\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "pred_class = np.argmax(probs,axis=1)\n",
    "true_class = np.argmax(y_test, axis=1)\n",
    "\n",
    "cm=confusion_matrix(true_class, pred_class)\n",
    "class_names = unique_labels(true_class, pred_class)\n",
    "print(cm)\n",
    "print(class_names)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "\n",
    "C = cm\n",
    "divisor = np.zeros((2,2))\n",
    "divisor[0][:] = 117\n",
    "divisor[1][:] = 483\n",
    "cm_normalised=np.divide(cm, divisor)\n",
    "print(np.transpose(C.sum(axis=1)))\n",
    "print(divisor)\n",
    "cm_normalised = np.round(cm_normalised, 2)\n",
    "disp = ConfusionMatrixDisplay(cm_normalised, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues, values_format='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Za6ZoHvNoFak",
    "outputId": "a641839f-23dd-4f8f-eafe-10ed3e6979ca"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "pred_class = np.argmax(probs, axis=1)\n",
    "true_class = np.argmax(y_test, axis=1)\n",
    "\n",
    "precision = precision_score(true_class, pred_class, average='weighted')\n",
    "recall = recall_score(true_class, pred_class, average='weighted')\n",
    "f1 = f1_score(true_class, pred_class, average='weighted')\n",
    "\n",
    "print(f\"Precision (Weighted): {precision:.2f}\")\n",
    "print(f\"Recall (Weighted): {recall:.2f}\")\n",
    "print(f\"F1-score (Weighted): {f1:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FMdlbRvPNR9Z",
    "outputId": "e20cafa8-df78-4e87-fc0d-cfdc0be8f9a2"
   },
   "outputs": [],
   "source": [
    "TP = np.diag(cm)\n",
    "FP = cm.sum(axis=0) - TP\n",
    "FN = cm.sum(axis=1) - TP\n",
    "\n",
    "precision_per_class = TP / (TP + FP)\n",
    "recall_per_class = TP / (TP + FN)\n",
    "f1_per_class = 2 * (precision_per_class * recall_per_class) / (precision_per_class + recall_per_class)\n",
    "\n",
    "weights = cm.sum(axis=1) / cm.sum()\n",
    "precision_weighted = np.sum(precision_per_class * weights)\n",
    "recall_weighted = np.sum(recall_per_class * weights)\n",
    "f1_weighted = np.sum(f1_per_class * weights)\n",
    "\n",
    "\n",
    "print(f\"Precision (Weighted): {precision_weighted:.2f}\")\n",
    "print(f\"Recall (Weighted): {recall_weighted:.2f}\")\n",
    "print(f\"F1-score (Weighted): {f1_weighted:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "92eqch_21Og1"
   },
   "source": [
    "This is optional visualisation for those who are interested in interpreting their results. MIT License: Copyright (c) 2018 Ben Trevett."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1YiQh8awkPp3"
   },
   "outputs": [],
   "source": [
    "def plot_filtered_images(images, filters, n_filters=None, normalize=True):\n",
    "\n",
    "    images = torch.cat([i.unsqueeze(0) for i in images], dim=0).cpu()\n",
    "    filters = filters.cpu()\n",
    "\n",
    "    if n_filters is not None:\n",
    "        filters = filters[:n_filters]\n",
    "\n",
    "    n_images = images.shape[0]\n",
    "    n_filters = filters.shape[0]\n",
    "\n",
    "    filtered_images = F.conv2d(images, filters)\n",
    "\n",
    "    fig = plt.figure(figsize=(30, 30))\n",
    "\n",
    "    for i in range(n_images):\n",
    "\n",
    "        image = images[i]\n",
    "\n",
    "        if normalize:\n",
    "            image = normalize_image(image)\n",
    "\n",
    "        ax = fig.add_subplot(n_images, n_filters+1, i+1+(i*n_filters))\n",
    "        ax.imshow(image.permute(1, 2, 0).numpy())\n",
    "        ax.set_title('Original')\n",
    "        ax.axis('off')\n",
    "\n",
    "        for j in range(n_filters):\n",
    "            image = filtered_images[i][j]\n",
    "\n",
    "            if normalize:\n",
    "                image = normalize_image(image)\n",
    "\n",
    "            ax = fig.add_subplot(n_images, n_filters+1, i+1+(i*n_filters)+j+1)\n",
    "            ax.imshow(image.numpy(), cmap='bone')\n",
    "            ax.set_title(f'Filter {j+1}')\n",
    "            ax.axis('off')\n",
    "\n",
    "    fig.subplots_adjust(hspace=-0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 843
    },
    "id": "0yvqclEk6cuk",
    "outputId": "960695c7-f2aa-4e59-e6dc-ddbd97604d72"
   },
   "outputs": [],
   "source": [
    "N_IMAGES = 5\n",
    "N_FILTERS = 7\n",
    "\n",
    "images = [image for image, label in [test_ds[i] for i in range(N_IMAGES)]]\n",
    "filters = model.features[0].weight.data\n",
    "\n",
    "plot_filtered_images(images, filters, N_FILTERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q-1uV_5wkWWt"
   },
   "outputs": [],
   "source": [
    "def plot_filters(filters, normalize = True):\n",
    "\n",
    "    filters = filters.cpu()\n",
    "\n",
    "    n_filters = filters.shape[0]\n",
    "\n",
    "    rows = int(np.sqrt(n_filters))\n",
    "    cols = int(np.sqrt(n_filters))\n",
    "\n",
    "    fig = plt.figure(figsize = (30, 15))\n",
    "\n",
    "    for i in range(rows*cols):\n",
    "\n",
    "        image = filters[i]\n",
    "\n",
    "        if normalize:\n",
    "            image = normalize_image(image)\n",
    "\n",
    "        ax = fig.add_subplot(rows, cols, i+1)\n",
    "        ax.imshow(image.permute(1, 2, 0))\n",
    "        ax.axis('off')\n",
    "\n",
    "    fig.subplots_adjust(wspace = -0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DTGOxF94kgBE",
    "outputId": "af161f80-bbdf-4107-9319-b3f72336d20d"
   },
   "outputs": [],
   "source": [
    "plot_filters(filters)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
